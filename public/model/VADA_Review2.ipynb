{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CWT8Hlb-LFBx",
        "outputId": "66df4384-ef20-46d1-98bd-e5056f32d8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.14.1-cp310-cp310-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.11.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.14.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.2)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "Successfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (0.56.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba) (0.39.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.18 in /usr/local/lib/python3.10/dist-packages (from numba) (1.23.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba) (67.7.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.14.0-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.2/451.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.23.5)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Collecting flatbuffers<3.0,>=1.12 (from tf2onnx)\n",
            "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.4.1->tf2onnx) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4)\n",
            "Installing collected packages: flatbuffers, onnx, tf2onnx\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "Successfully installed flatbuffers-2.0.7 onnx-1.13.1 tf2onnx-1.14.0\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!pip install onnxruntime\n",
        "!pip install librosa\n",
        "!pip install numpy==1.23.5\n",
        "!pip install numba\n",
        "!pip install scipy\n",
        "!pip install tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBjYp_WbxD87"
      },
      "outputs": [],
      "source": [
        "#importa\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from keras import layers\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.metrics import Metric\n",
        "from keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "import copy\n",
        "import cv2\n",
        "import librosa\n",
        "import librosa.display\n",
        "import logging\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import onnx\n",
        "import onnxruntime as ort\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import typing\n",
        "import yaml\n",
        "from itertools import groupby"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLJd55svRIJW"
      },
      "outputs": [],
      "source": [
        "#argumentors\n",
        "\n",
        "class Image:\n",
        "    \"\"\" Image class for storing image data and metadata\n",
        "\n",
        "    Args:\n",
        "        image (str or np.ndarray): Path to image or numpy.ndarray\n",
        "        method (int, optional): OpenCV method for reading image. Defaults to cv2.IMREAD_COLOR.\n",
        "        path (str, optional): Path to image. Defaults to \"\".\n",
        "        color (str, optional): Color format of image. Defaults to \"\".\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        image: typing.Union[str, np.ndarray],\n",
        "        method: int = cv2.IMREAD_COLOR,\n",
        "        path: str = \"\",\n",
        "        color: str = \"BGR\"\n",
        "        ) -> None:\n",
        "        \n",
        "        if isinstance(image, str):\n",
        "            if not os.path.exists(image):\n",
        "                raise FileNotFoundError(f\"Image {image} not found.\")\n",
        "\n",
        "            self.image = cv2.imread(image, method)\n",
        "            self.path = image\n",
        "            self.color = \"BGR\"\n",
        "\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            self.image = image\n",
        "            self.path = path\n",
        "            self.color = color\n",
        "\n",
        "        else:\n",
        "            raise TypeError(f\"Image must be either path to image or numpy.ndarray, not {type(image)}\")\n",
        "\n",
        "        self.method = method\n",
        "\n",
        "        if self.image is None:\n",
        "            return None\n",
        "\n",
        "        # save width, height and channels\n",
        "        self.width = self.image.shape[1]\n",
        "        self.height = self.image.shape[0]\n",
        "        self.channels = 1 if len(self.image.shape) == 2 else self.image.shape[2]\n",
        "\n",
        "    @property\n",
        "    def shape(self) -> tuple:\n",
        "        return self.image.shape\n",
        "\n",
        "    @property\n",
        "    def center(self) -> tuple:\n",
        "        return (self.width // 2, self.height // 2)\n",
        "\n",
        "    def RGB(self) -> np.ndarray:\n",
        "        if self.color == \"RGB\":\n",
        "            return self.image\n",
        "        elif self.color == \"BGR\":\n",
        "            return cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown color format {self.color}\")\n",
        "        \n",
        "    def HSV(self) -> np.ndarray:\n",
        "        if self.color == \"BGR\":\n",
        "            return cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
        "        elif self.color == \"RGB\":\n",
        "            return cv2.cvtColor(self.image, cv2.COLOR_RGB2HSV)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown color format {self.color}\")\n",
        "\n",
        "    def update(self, image: np.ndarray):\n",
        "        if isinstance(image, np.ndarray):\n",
        "            self.image = image\n",
        "\n",
        "            # save width, height and channels\n",
        "            self.width = self.image.shape[1]\n",
        "            self.height = self.image.shape[0]\n",
        "            self.channels = 1 if len(self.image.shape) == 2 else self.image.shape[2]\n",
        "\n",
        "            return self\n",
        "\n",
        "        else:\n",
        "            raise TypeError(f\"image must be numpy.ndarray, not {type(image)}\")\n",
        "\n",
        "    def flip(self, axis: int = 0):\n",
        "        \"\"\" Flip image along x or y axis\n",
        "\n",
        "        Args:\n",
        "            axis (int, optional): Axis along which image will be flipped. Defaults to 0.\n",
        "\n",
        "        Returns:\n",
        "            Object with flipped points\n",
        "        \"\"\"\n",
        "        # axis must be either 0 or 1\n",
        "        if axis not in [0, 1]:\n",
        "            raise ValueError(f\"axis must be either 0 or 1, not {axis}\")\n",
        "\n",
        "        self.image = self.image[:, ::-1] if axis == 0 else self.image[::-1]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def numpy(self) -> np.ndarray:\n",
        "        return self.image\n",
        "    \n",
        "    def __call__(self) -> np.ndarray:\n",
        "        return self.image\n",
        "\n",
        "\"\"\" Implemented augmentors:\n",
        "- RandomBrightness\n",
        "- RandomRotate\n",
        "- RandomErodeDilate\n",
        "- RandomSharpen\n",
        "- RandomGaussianBlur\n",
        "\"\"\"\n",
        "\n",
        "def randomness_decorator(func):\n",
        "    \"\"\" Decorator for randomness \"\"\"\n",
        "    def wrapper(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Decorator for randomness and type checking\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be adjusted\n",
        "            annotation (typing.Any): Annotation to be adjusted\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Adjusted image\n",
        "            annotation (typing.Any): Adjusted annotation\n",
        "        \"\"\"\n",
        "        # check if image is Image object\n",
        "        if not isinstance(image, Image):\n",
        "            self.logger.error(f\"image must be Image object, not {type(image)}, skipping augmentor\")\n",
        "            return image, annotation\n",
        "\n",
        "        if np.random.rand() > self._random_chance:\n",
        "            return image, annotation\n",
        "\n",
        "        # return result of function\n",
        "        return func(self, image, annotation)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "class Augmentor:\n",
        "    \"\"\" Object that should be inherited by all augmentors\n",
        "\n",
        "    Args:\n",
        "        random_chance (float, optional): Chance of applying the augmentor. Where 0.0 is never and 1.0 is always. Defaults to 0.5.\n",
        "        log_level (int, optional): Log level for the augmentor. Defaults to logging.INFO.\n",
        "    \"\"\"\n",
        "    def __init__(self, random_chance: float=0.5, log_level: int = logging.INFO) -> None:\n",
        "        self._random_chance = random_chance\n",
        "        self._log_level = log_level\n",
        "\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "        assert 0 <= self._random_chance <= 1.0, \"random chance must be between 0.0 and 1.0\"\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        # do the augmentation here\n",
        "        return image, annotation\n",
        "\n",
        "\n",
        "class RandomBrightness(Augmentor):\n",
        "    \"\"\" Randomly adjust image brightness \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        random_chance: float = 0.5,\n",
        "        delta: int = 100,\n",
        "        log_level: int = logging.INFO,\n",
        "        ) -> None:\n",
        "        \"\"\" Randomly adjust image brightness\n",
        "\n",
        "        Args:\n",
        "            random_chance (float, optional): Chance of applying the augmentor. Where 0.0 is never and 1.0 is always. Defaults to 0.5.\n",
        "            delta (int, optional): Integer value for brightness adjustment. Defaults to 100.\n",
        "            log_level (int, optional): Log level for the augmentor. Defaults to logging.INFO.\n",
        "        \"\"\"\n",
        "        super(RandomBrightness, self).__init__(random_chance, log_level)\n",
        "\n",
        "        assert 0 <= delta <= 255.0, \"Delta must be between 0.0 and 255.0\"\n",
        "\n",
        "        self._delta = delta\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Randomly adjust image brightness\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be adjusted\n",
        "            annotation (typing.Any): Annotation to be adjusted\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Adjusted image\n",
        "            annotation (typing.Any): Adjusted annotation if necessary\n",
        "        \"\"\"\n",
        "        value = 1 + np.random.uniform(-self._delta, self._delta) / 255\n",
        "\n",
        "        hsv = np.array(image.HSV(), dtype = np.float32)\n",
        "\n",
        "        hsv[:, :, 1] = hsv[:, :, 1] * value\n",
        "        hsv[:, :, 2] = hsv[:, :, 2] * value\n",
        "\n",
        "        hsv = np.uint8(np.clip(hsv, 0, 255))\n",
        "\n",
        "        img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "        image.update(img)\n",
        "\n",
        "        return image, annotation\n",
        "\n",
        "\n",
        "class RandomRotate(Augmentor):\n",
        "    \"\"\" Randomly rotate image\"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        random_chance: float = 0.5,\n",
        "        angle: typing.Union[int, typing.List]=30, \n",
        "        borderValue: typing.Tuple[int, int, int]=None,\n",
        "        log_level: int = logging.INFO,\n",
        "        ) -> None:\n",
        "        \"\"\" Randomly rotate image \n",
        "\n",
        "        Args:\n",
        "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
        "            angle (int, list): Integer value or list of integer values for image rotation\n",
        "            borderValue (tuple): Tuple of 3 integers, setting border color for image rotation\n",
        "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
        "        \"\"\"\n",
        "        super(RandomRotate, self).__init__(random_chance, log_level)\n",
        "\n",
        "        self._angle = angle\n",
        "        self._borderValue = borderValue\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Randomly rotate image\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be adjusted\n",
        "            annotation (typing.Any): Annotation to be adjusted\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Adjusted image\n",
        "            annotation (typing.Any): Adjusted annotation\n",
        "        \"\"\"\n",
        "        # check if angle is list of angles or signle angle value\n",
        "        if isinstance(self._angle, list):\n",
        "            angle = float(np.random.choice(self._angle))\n",
        "        else:\n",
        "            angle = float(np.random.uniform(-self._angle, self._angle))\n",
        "\n",
        "        # generate random border color\n",
        "        borderValue = np.random.randint(0, 255, 3) if self._borderValue is None else self._borderValue\n",
        "        borderValue = [int(v) for v in borderValue]\n",
        "\n",
        "        # grab the dimensions of the image and then determine the centre\n",
        "        center_x, center_y = image.center\n",
        "\n",
        "        # grab the rotation matrix (applying the negative of the\n",
        "        # angle to rotate clockwise), then grab the sine and cosine\n",
        "        # (i.e., the rotation components of the matrix)\n",
        "        M = cv2.getRotationMatrix2D((center_x, center_y), angle, 1.0)\n",
        "        cos = np.abs(M[0, 0])\n",
        "        sin = np.abs(M[0, 1])\n",
        "\n",
        "        # compute the new bounding dimensions of the image\n",
        "        nW = int((image.height * sin) + (image.width * cos))\n",
        "        nH = int((image.height * cos) + (image.width * sin))\n",
        "\n",
        "        # adjust the rotation matrix to take into account translation\n",
        "        M[0, 2] += (nW / 2) - center_x\n",
        "        M[1, 2] += (nH / 2) - center_y\n",
        "\n",
        "        # perform the actual rotation and return the image\n",
        "        img = cv2.warpAffine(image.numpy(), M, (nW, nH), borderValue=borderValue)\n",
        "        image.update(img)\n",
        "\n",
        "        return image, annotation\n",
        "\n",
        "\n",
        "class RandomErodeDilate(Augmentor):\n",
        "    \"\"\" Randomly erode and dilate image\"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        random_chance: float = 0.5,\n",
        "        kernel_size: typing.Tuple[int, int]=(1, 1), \n",
        "        log_level: int = logging.INFO,\n",
        "        ) -> None:\n",
        "        \"\"\" Randomly erode and dilate image\n",
        "        \n",
        "        Args:\n",
        "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
        "            kernel_size (tuple): Tuple of 2 integers, setting kernel size for erosion and dilation\n",
        "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
        "        \"\"\"\n",
        "        super(RandomErodeDilate, self).__init__(random_chance, log_level)\n",
        "        self._kernel_size = kernel_size\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Randomly erode and dilate image\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be eroded and dilated\n",
        "            annotation (typing.Any): Annotation to be adjusted\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Eroded and dilated image\n",
        "            annotation (typing.Any): Adjusted annotation if necessary\n",
        "        \"\"\"\n",
        "        kernel = np.ones(self._kernel_size, np.uint8)\n",
        "\n",
        "        if np.random.rand() <= 0.5:\n",
        "            img = cv2.erode(image.numpy(), kernel, iterations=1)\n",
        "        else:\n",
        "            img = cv2.dilate(image.numpy(), kernel, iterations=1)\n",
        "\n",
        "        image.update(img)\n",
        "\n",
        "        return image, annotation\n",
        "\n",
        "\n",
        "class RandomSharpen(Augmentor):\n",
        "    \"\"\" Randomly sharpen image\"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        random_chance: float = 0.5,\n",
        "        alpha: float = 0.25,\n",
        "        lightness_range: typing.Tuple = (0.75, 2.0),\n",
        "        kernel: np.ndarray = None,\n",
        "        kernel_anchor: np.ndarray = None,\n",
        "        log_level: int = logging.INFO,\n",
        "        ) -> None:\n",
        "        \"\"\" Randomly sharpen image\n",
        "        \n",
        "        Args:\n",
        "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
        "            alpha (float): Float between 0.0 and 1.0 setting bounds for random probability\n",
        "            lightness_range (tuple): Tuple of 2 floats, setting bounds for random lightness change\n",
        "            kernel (np.ndarray): Numpy array of kernel for image convolution\n",
        "            kernel_anchor (np.ndarray): Numpy array of kernel anchor for image convolution\n",
        "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
        "        \"\"\"\n",
        "        super(RandomSharpen, self).__init__(random_chance, log_level)\n",
        "\n",
        "        self._alpha_range = (alpha, 1.0)\n",
        "        self._ligtness_range = lightness_range\n",
        "        self._lightness_anchor = 8\n",
        "\n",
        "        self._kernel = np.array([[-1, -1, -1], [-1,  1, -1], [-1, -1, -1]], dtype=np.float32) if kernel is None else kernel\n",
        "        self._kernel_anchor = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]], dtype=np.float32) if kernel_anchor is None else kernel_anchor\n",
        "\n",
        "        assert 0 <= alpha <= 1.0, \"Alpha must be between 0.0 and 1.0\"\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Randomly sharpen image\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be sharpened\n",
        "            annotation (typing.Any): Annotation to be adjusted\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Sharpened image\n",
        "            annotation (typing.Any): Adjusted annotation if necessary\n",
        "        \"\"\"\n",
        "        lightness = np.random.uniform(*self._ligtness_range)\n",
        "        alpha = np.random.uniform(*self._alpha_range)\n",
        "\n",
        "        kernel = self._kernel_anchor  * (self._lightness_anchor + lightness) + self._kernel\n",
        "        kernel -= self._kernel_anchor\n",
        "        kernel = (1 - alpha) * self._kernel_anchor + alpha * kernel\n",
        "\n",
        "        # Apply sharpening to each channel\n",
        "        r, g, b = cv2.split(image.numpy())\n",
        "        r_sharp = cv2.filter2D(r, -1, kernel)\n",
        "        g_sharp = cv2.filter2D(g, -1, kernel)\n",
        "        b_sharp = cv2.filter2D(b, -1, kernel)\n",
        "\n",
        "        # Merge the sharpened channels back into the original image\n",
        "        image.update(cv2.merge([r_sharp, g_sharp, b_sharp]))\n",
        "\n",
        "        return image, annotation\n",
        "    \n",
        "\n",
        "class RandomGaussianBlur(Augmentor):\n",
        "    \"\"\" Randomly erode and dilate image\"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        random_chance: float = 0.5,\n",
        "        log_level: int = logging.INFO,\n",
        "        sigma: typing.Union[int, float] = 0.5,\n",
        "        ) -> None:\n",
        "        \"\"\" Randomly erode and dilate image\n",
        "        \n",
        "        Args:\n",
        "            random_chance (float): Float between 0.0 and 1.0 setting bounds for random probability. Defaults to 0.5.\n",
        "            log_level (int): Log level for the augmentor. Defaults to logging.INFO.\n",
        "            sigma (int, float): standard deviation of the Gaussian kernel\n",
        "        \"\"\"\n",
        "        super(RandomGaussianBlur, self).__init__(random_chance, log_level)\n",
        "        self.sigma = sigma\n",
        "\n",
        "    @randomness_decorator\n",
        "    def __call__(self, image: Image, annotation: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Randomly blurs an image with a Gaussian filter\n",
        "\n",
        "        Args:\n",
        "            image (Image): Image to be blurred\n",
        "            annotation (typing.Any): Annotation to be blurred\n",
        "\n",
        "        Returns:\n",
        "            image (Image): Blurred image\n",
        "            annotation (typing.Any): Blurred annotation if necessary\n",
        "        \"\"\"\n",
        "        img = cv2.GaussianBlur(image.numpy(), (0, 0), self.sigma)\n",
        "\n",
        "        image.update(img)\n",
        "\n",
        "        return image, annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0Nfl8phRIFV"
      },
      "outputs": [],
      "source": [
        "#configs\n",
        "class BaseModelConfigs:\n",
        "    def __init__(self):\n",
        "        self.model_path = None\n",
        "\n",
        "    def serialize(self):\n",
        "        # get object attributes\n",
        "        return self.__dict__\n",
        "\n",
        "    def save(self, name: str='configs.yaml'):\n",
        "        if self.model_path is None:\n",
        "            raise Exception(\"Model path is not specified\")\n",
        "\n",
        "        # create directory if not exist\n",
        "        if not os.path.exists(self.model_path):\n",
        "            os.makedirs(self.model_path)\n",
        "\n",
        "        with open(os.path.join(self.model_path, name), 'w') as f:\n",
        "            yaml.dump(self.serialize(), f)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(configs_path: str):\n",
        "        with open(configs_path, 'r') as f:\n",
        "            configs = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "        config = BaseModelConfigs()\n",
        "        for key, value in configs.items():\n",
        "            setattr(config, key, value)\n",
        "\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g5TmUJ8SGXJ"
      },
      "outputs": [],
      "source": [
        "#transformers\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s %(name)s: %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "\n",
        "class Transformer:\n",
        "    def __init__(self, log_level: int = logging.INFO) -> None:\n",
        "        self._log_level = log_level\n",
        "\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "    def __call__(self, data: typing.Any, label: typing.Any, *args, **kwargs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class ExpandDims(Transformer):\n",
        "    def __init__(self, axis: int=-1):\n",
        "        self.axis = axis\n",
        "\n",
        "    def __call__(self, data: np.ndarray, label: np.ndarray):\n",
        "        return np.expand_dims(data, self.axis), label\n",
        "\n",
        "class ImageResizer(Transformer):\n",
        "    \"\"\"Resize image to (width, height)\n",
        "    \n",
        "    Attributes:\n",
        "        width (int): Width of image\n",
        "        height (int): Height of image\n",
        "        keep_aspect_ratio (bool): Whether to keep aspect ratio of image\n",
        "        padding_color (typing.Tuple[int]): Color to pad image\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        width: int, \n",
        "        height: int, \n",
        "        keep_aspect_ratio: bool=False, \n",
        "        padding_color: typing.Tuple[int]=(0, 0, 0)\n",
        "        ) -> None:\n",
        "        self._width = width\n",
        "        self._height = height\n",
        "        self._keep_aspect_ratio = keep_aspect_ratio\n",
        "        self._padding_color = padding_color\n",
        "\n",
        "    @staticmethod\n",
        "    def resize_maintaining_aspect_ratio(image: np.ndarray, width_target: int, height_target: int, padding_color: typing.Tuple[int]=(0, 0, 0)) -> np.ndarray:\n",
        "        \"\"\" Resize image maintaining aspect ratio and pad with padding_color.\n",
        "\n",
        "        Args:\n",
        "            image (np.ndarray): Image to resize\n",
        "            width_target (int): Target width\n",
        "            height_target (int): Target height\n",
        "            padding_color (typing.Tuple[int]): Color to pad image\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Resized image\n",
        "        \"\"\"\n",
        "        height, width = image.shape[:2]\n",
        "        ratio = min(width_target / width, height_target / height)\n",
        "        new_w, new_h = int(width * ratio), int(height * ratio)\n",
        "\n",
        "        resized_image = cv2.resize(image, (new_w, new_h))\n",
        "        delta_w = width_target - new_w\n",
        "        delta_h = height_target - new_h\n",
        "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "\n",
        "        new_image = cv2.copyMakeBorder(resized_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=padding_color)\n",
        "\n",
        "        return new_image\n",
        "\n",
        "    def __call__(self, image: Image, label: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        # Maintains aspect ratio and resizes with padding.\n",
        "        image_numpy = image.numpy()\n",
        "        if self._keep_aspect_ratio:\n",
        "            image_numpy = self.resize_maintaining_aspect_ratio(image.numpy(), self._width, self._height, self._padding_color)\n",
        "\n",
        "            # TODO - Fix this\n",
        "            # if isinstance(label, np.ndarray):\n",
        "            #     label = self.resize_maintaining_aspect_ratio(label, self._width, self._height, self._padding_color)\n",
        "\n",
        "        else:   \n",
        "            # Resizes without maintaining aspect ratio.\n",
        "            image_numpy = cv2.resize(image_numpy, (self._width, self._height))\n",
        "\n",
        "        image.update(image_numpy)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class LabelIndexer(Transformer):\n",
        "    \"\"\"Convert label to index by vocab\n",
        "    \n",
        "    Attributes:\n",
        "        vocab (typing.List[str]): List of characters in vocab\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        vocab: typing.List[str]\n",
        "        ) -> None:\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, data: np.ndarray, label: np.ndarray):\n",
        "        return data, np.array([self.vocab.index(l) for l in label if l in self.vocab])\n",
        "\n",
        "class LabelPadding(Transformer):\n",
        "    \"\"\"Pad label to max_word_length\n",
        "    \n",
        "    Attributes:\n",
        "        max_word_length (int): Maximum length of label\n",
        "        padding_value (int): Value to pad\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        max_word_length: int, \n",
        "        padding_value: int\n",
        "        ) -> None:\n",
        "        self.max_word_length = max_word_length\n",
        "        self.padding_value = padding_value\n",
        "\n",
        "    def __call__(self, data: np.ndarray, label: np.ndarray):\n",
        "        return data, np.pad(label, (0, self.max_word_length - len(label)), 'constant', constant_values=self.padding_value)\n",
        "\n",
        "class SpectrogramPadding(Transformer):\n",
        "    \"\"\"Pad spectrogram to max_spectrogram_length\n",
        "    \n",
        "    Attributes:\n",
        "        max_spectrogram_length (int): Maximum length of spectrogram\n",
        "        padding_value (int): Value to pad\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        max_spectrogram_length: int, \n",
        "        padding_value: int\n",
        "        ) -> None:\n",
        "        self.max_spectrogram_length = max_spectrogram_length\n",
        "        self.padding_value = padding_value\n",
        "\n",
        "    def __call__(self, spectrogram: np.ndarray, label: np.ndarray):\n",
        "        padded_spectrogram = np.pad(spectrogram, ((self.max_spectrogram_length - spectrogram.shape[0], 0),(0,0)), mode='constant', constant_values=self.padding_value)\n",
        "\n",
        "        return padded_spectrogram, label\n",
        "\n",
        "class ImageShowCV2(Transformer):\n",
        "    \"\"\"Show image for visual inspection\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        verbose: bool=True, \n",
        "        log_level: int = logging.INFO,\n",
        "        name: str = 'Image'\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            verbose (bool): Whether to log label\n",
        "            log_level (int): Logging level (default: logging.INFO)\n",
        "            name (str): Name of window to show image\n",
        "        \"\"\"\n",
        "        super(ImageShowCV2, self).__init__(log_level=log_level)\n",
        "        self.verbose = verbose\n",
        "        self.name = name\n",
        "\n",
        "    def __call__(self, image: Image, label: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Show image for visual inspection\n",
        "\n",
        "        Args:\n",
        "            data (np.ndarray): Image data\n",
        "            label (np.ndarray): Label data\n",
        "        \n",
        "        Returns:\n",
        "            data (np.ndarray): Image data\n",
        "            label (np.ndarray): Label data (unchanged)\n",
        "        \"\"\"\n",
        "        if self.verbose:\n",
        "            if isinstance(label, (str, int, float)):\n",
        "                self.logger.info(f'Label: {label}')\n",
        "\n",
        "        cv2.imshow(self.name, image.numpy())\n",
        "        cv2.waitKey(0)\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-0gYnyNRIB7"
      },
      "outputs": [],
      "source": [
        "#dataProviders\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s %(name)s: %(message)s')\n",
        "\n",
        "class DataProvider:\n",
        "    def __init__(\n",
        "        self, \n",
        "        dataset: typing.Union[str, list, pd.DataFrame],\n",
        "        data_preprocessors: typing.List[typing.Callable] = None,\n",
        "        batch_size: int = 4,\n",
        "        shuffle: bool = True,\n",
        "        initial_epoch: int = 1,\n",
        "        augmentors: typing.List[Augmentor] = None,\n",
        "        transformers: typing.List[Transformer] = None,\n",
        "        skip_validation: bool = True,\n",
        "        limit: int = None,\n",
        "        use_cache: bool = False,\n",
        "        log_level: int = logging.INFO,\n",
        "        ) -> None:\n",
        "        \"\"\" Standardised object for providing data to a model while training.\n",
        "\n",
        "        Attributes:\n",
        "            dataset (str, list, pd.DataFrame): Path to dataset, list of data or pandas dataframe of data.\n",
        "            data_preprocessors (list): List of data preprocessors. (e.g. [read image, read audio, etc.])\n",
        "            batch_size (int): The number of samples to include in each batch. Defaults to 4.\n",
        "            shuffle (bool): Whether to shuffle the data. Defaults to True.\n",
        "            initial_epoch (int): The initial epoch. Defaults to 1.\n",
        "            augmentors (list, optional): List of augmentor functions. Defaults to None.\n",
        "            transformers (list, optional): List of transformer functions. Defaults to None.\n",
        "            skip_validation (bool, optional): Whether to skip validation. Defaults to True.\n",
        "            limit (int, optional): Limit the number of samples in the dataset. Defaults to None.\n",
        "            use_cache (bool, optional): Whether to cache the dataset. Defaults to False.\n",
        "            log_level (int, optional): The log level. Defaults to logging.INFO.\n",
        "        \"\"\"\n",
        "        self._dataset = dataset\n",
        "        self._data_preprocessors = [] if data_preprocessors is None else data_preprocessors\n",
        "        self._batch_size = batch_size\n",
        "        self._shuffle = shuffle\n",
        "        self._epoch = initial_epoch\n",
        "        self._augmentors = [] if augmentors is None else augmentors\n",
        "        self._transformers = [] if transformers is None else transformers\n",
        "        self._skip_validation = skip_validation\n",
        "        self._limit = limit\n",
        "        self._use_cache = use_cache\n",
        "        self._step = 0\n",
        "        self._cache = {}\n",
        "        self._on_epoch_end_remove = []\n",
        "\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.setLevel(log_level)\n",
        "\n",
        "        # Validate dataset\n",
        "        if not skip_validation:\n",
        "            self._dataset = self.validate(dataset, skip_validation, limit)\n",
        "        else:\n",
        "            self.logger.info(\"Skipping Dataset validation...\")\n",
        "\n",
        "        if limit:\n",
        "            self.logger.info(f\"Limiting dataset to {limit} samples.\")\n",
        "            self._dataset = self._dataset[:limit]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\" Denotes the number of batches per epoch \"\"\"\n",
        "        return int(np.ceil(len(self._dataset) / self._batch_size))\n",
        "\n",
        "    @property\n",
        "    def augmentors(self) -> typing.List[Augmentor]:\n",
        "        \"\"\" Return augmentors \"\"\"\n",
        "        return self._augmentors\n",
        "\n",
        "    @augmentors.setter\n",
        "    def augmentors(self, augmentors: typing.List[Augmentor]):\n",
        "        \"\"\" Decorator for adding augmentors to the DataProvider \"\"\"\n",
        "        for augmentor in augmentors:\n",
        "            if isinstance(augmentor, Augmentor):\n",
        "                if self._augmentors is not None:\n",
        "                    self._augmentors.append(augmentor)\n",
        "                else:\n",
        "                    self._augmentors = [augmentor]\n",
        "\n",
        "            else:\n",
        "                self.logger.warning(f\"Augmentor {augmentor} is not an instance of Augmentor.\")\n",
        "\n",
        "        return self._augmentors\n",
        "\n",
        "    @property\n",
        "    def transformers(self) -> typing.List[Transformer]:\n",
        "        \"\"\" Return transformers \"\"\"\n",
        "        return self._transformers\n",
        "\n",
        "    @transformers.setter\n",
        "    def transformers(self, transformers: typing.List[Transformer]):\n",
        "        \"\"\" Decorator for adding transformers to the DataProvider \"\"\"\n",
        "        for transformer in transformers:\n",
        "            if isinstance(transformer, Transformer):\n",
        "                if self._transformers is not None:\n",
        "                    self._transformers.append(transformer)\n",
        "                else:\n",
        "                    self._transformers = [transformer]\n",
        "\n",
        "            else:\n",
        "                self.logger.warning(f\"Transformer {transformer} is not an instance of Transformer.\")\n",
        "\n",
        "        return self._transformers\n",
        "\n",
        "    @property\n",
        "    def epoch(self) -> int:\n",
        "        \"\"\" Return Current Epoch\"\"\"\n",
        "        return self._epoch\n",
        "\n",
        "    @property\n",
        "    def step(self) -> int:\n",
        "        \"\"\" Return Current Step\"\"\"\n",
        "        return self._step\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        \"\"\" Shuffle training dataset and increment epoch counter at the end of each epoch. \"\"\"\n",
        "        self._epoch += 1\n",
        "        if self._shuffle:\n",
        "            np.random.shuffle(self._dataset)\n",
        "\n",
        "        # Remove any samples that were marked for removal\n",
        "        for remove in self._on_epoch_end_remove:\n",
        "            self.logger.warn(f\"Removing {remove} from dataset.\")\n",
        "            self._dataset.remove(remove)\n",
        "        self._on_epoch_end_remove = []\n",
        "\n",
        "    def validate_list_dataset(self, dataset: list, skip_validation: bool = False) -> list:\n",
        "        \"\"\" Validate a list dataset \"\"\"\n",
        "        validated_data = [data for data in tqdm(dataset, desc=\"Validating Dataset\") if os.path.exists(data[0])]\n",
        "        if not validated_data:\n",
        "            raise FileNotFoundError(\"No valid data found in dataset.\")\n",
        "\n",
        "        return validated_data\n",
        "\n",
        "    def validate(self, dataset: typing.Union[str, list, pd.DataFrame], skip_validation: bool) -> list:\n",
        "        \"\"\" Validate the dataset and return the dataset \"\"\"\n",
        "\n",
        "        if isinstance(dataset, str):\n",
        "            if os.path.exists(dataset):\n",
        "                return dataset\n",
        "        elif isinstance(dataset, list):\n",
        "            return self.validate_list_dataset(dataset, skip_validation)\n",
        "        elif isinstance(dataset, pd.DataFrame):\n",
        "            return self.validate_list_dataset(dataset.values.tolist(), skip_validation)\n",
        "        else:\n",
        "            raise TypeError(\"Dataset must be a path, list or pandas dataframe.\")\n",
        "\n",
        "    def split(self, split: float = 0.9, shuffle: bool = True) -> typing.Tuple[typing.Any, typing.Any]:\n",
        "        \"\"\" Split current data provider into training and validation data providers. \n",
        "        \n",
        "        Args:\n",
        "            split (float, optional): The split ratio. Defaults to 0.9.\n",
        "            shuffle (bool, optional): Whether to shuffle the dataset. Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            train_data_provider (tf.keras.utils.Sequence): The training data provider.\n",
        "            val_data_provider (tf.keras.utils.Sequence): The validation data provider.\n",
        "        \"\"\"\n",
        "        if shuffle:\n",
        "            np.random.shuffle(self._dataset)\n",
        "            \n",
        "        train_data_provider, val_data_provider = copy.deepcopy(self), copy.deepcopy(self)\n",
        "        train_data_provider._dataset = self._dataset[:int(len(self._dataset) * split)]\n",
        "        val_data_provider._dataset = self._dataset[int(len(self._dataset) * split):]\n",
        "\n",
        "        return train_data_provider, val_data_provider\n",
        "\n",
        "    def to_csv(self, path: str, index: bool=False) -> None:\n",
        "        \"\"\" Save the dataset to a csv file \n",
        "\n",
        "        Args:\n",
        "            path (str): The path to save the csv file.\n",
        "            index (bool, optional): Whether to save the index. Defaults to False.\n",
        "        \"\"\"\n",
        "        df = pd.DataFrame(self._dataset)\n",
        "        df.to_csv(path, index=index)\n",
        "\n",
        "    def get_batch_annotations(self, index: int) -> typing.List:\n",
        "        \"\"\" Returns a batch of annotations by batch index in the dataset\n",
        "\n",
        "        Args:\n",
        "            index (int): The index of the batch in \n",
        "\n",
        "        Returns:\n",
        "            batch_annotations (list): A list of batch annotations\n",
        "        \"\"\"\n",
        "        self._step = index\n",
        "        start_index = index * self._batch_size\n",
        "\n",
        "        # Get batch indexes\n",
        "        batch_indexes = [i for i in range(start_index, start_index + self._batch_size) if i < len(self._dataset)]\n",
        "\n",
        "        # Read batch data\n",
        "        batch_annotations = [self._dataset[index] for index in batch_indexes]\n",
        "\n",
        "        return batch_annotations\n",
        "    \n",
        "    def __iter__(self):\n",
        "        \"\"\" Create a generator that iterate over the Sequence.\"\"\"\n",
        "        for item in (self[i] for i in range(len(self))):\n",
        "            yield item\n",
        "\n",
        "    def process_data(self, batch_data):\n",
        "        \"\"\" Process data batch of data \"\"\"\n",
        "        if self._use_cache and batch_data[0] in self._cache:\n",
        "            data, annotation = copy.deepcopy(self._cache[batch_data[0]])\n",
        "        else:\n",
        "            data, annotation = batch_data\n",
        "            for preprocessor in self._data_preprocessors:\n",
        "                data, annotation = preprocessor(data, annotation)\n",
        "            \n",
        "            if data is None or annotation is None:\n",
        "                self.logger.warning(\"Data or annotation is None, marking for removal on epoch end.\")\n",
        "                self._on_epoch_end_remove.append(batch_data)\n",
        "                return None, None\n",
        "            \n",
        "            if self._use_cache and batch_data[0] not in self._cache:\n",
        "                self._cache[batch_data[0]] = (copy.deepcopy(data), copy.deepcopy(annotation))\n",
        "\n",
        "        # Then augment, transform and postprocess the batch data\n",
        "        for objects in [self._augmentors, self._transformers]:\n",
        "            for object in objects:\n",
        "                data, annotation = object(data, annotation)\n",
        "\n",
        "        # Convert to numpy array if not already\n",
        "        if not isinstance(data, np.ndarray):\n",
        "            data = data.numpy()\n",
        "\n",
        "        # Convert to numpy array if not already\n",
        "        # TODO: This is a hack, need to fix this\n",
        "        if not isinstance(annotation, (np.ndarray, int, float, str, np.uint8, np.float)):\n",
        "            annotation = annotation.numpy()\n",
        "\n",
        "        return data, annotation\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        \"\"\" Returns a batch of data by batch index\"\"\"\n",
        "        dataset_batch = self.get_batch_annotations(index)\n",
        "        \n",
        "        # First read and preprocess the batch data\n",
        "        batch_data, batch_annotations = [], []\n",
        "        for index, batch in enumerate(dataset_batch):\n",
        "\n",
        "            data, annotation = self.process_data(batch)\n",
        "\n",
        "            if data is None or annotation is None:\n",
        "                self.logger.warning(\"Data or annotation is None, skipping.\")\n",
        "                continue\n",
        "\n",
        "            batch_data.append(data)\n",
        "            batch_annotations.append(annotation)\n",
        "\n",
        "        return np.array(batch_data), np.array(batch_annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4IVzbE0ufgM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xts3T5kURH9r"
      },
      "outputs": [],
      "source": [
        "#inferenceModel\n",
        "class OnnxInferenceModel:\n",
        "    \"\"\" Base class for all inference models that use onnxruntime \n",
        "\n",
        "    Attributes:\n",
        "        model_path (str, optional): Path to the model folder. Defaults to \"\".\n",
        "        force_cpu (bool, optional): Force the model to run on CPU or GPU. Defaults to GPU.\n",
        "        default_model_name (str, optional): Default model name. Defaults to \"model.onnx\".\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        model_path: str = \"\",\n",
        "        force_cpu: bool = False,\n",
        "        default_model_name: str = \"model.onnx\"\n",
        "        ):\n",
        "        \n",
        "        self.model_path = model_path\n",
        "        self.force_cpu = force_cpu\n",
        "        self.default_model_name = default_model_name\n",
        "\n",
        "        # check if model path is a directory with os path\n",
        "        if os.path.isdir(self.model_path):\n",
        "            self.model_path = os.path.join(self.model_path, self.default_model_name)\n",
        "\n",
        "        if not os.path.exists(self.model_path):\n",
        "            raise Exception(f\"Model path ({self.model_path}) does not exist\")\n",
        "\n",
        "        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if ort.get_device() == \"GPU\" and not force_cpu else ['CPUExecutionProvider']\n",
        "\n",
        "        self.model = ort.InferenceSession(self.model_path, providers=providers)\n",
        "\n",
        "        self.metadata = self.model.get_modelmeta().custom_metadata_map\n",
        "        if self.metadata:\n",
        "            # add metadata to self object\n",
        "            for key, value in self.metadata.items():\n",
        "                setattr(self, key, value) \n",
        "                \n",
        "        # Update providers priority to only CPUExecutionProvider\n",
        "        if self.force_cpu:\n",
        "            self.model.set_providers(['CPUExecutionProvider'])\n",
        "\n",
        "        self.input_shape = self.model.get_inputs()[0].shape[1:]\n",
        "        self.input_name = self.model._inputs_meta[0].name\n",
        "        self.output_name = self.model._outputs_meta[0].name\n",
        "\n",
        "    def predict(self, data: np.ndarray):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __call__(self, data: np.ndarray):\n",
        "        return self.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKi_k_dESwQM"
      },
      "outputs": [],
      "source": [
        "#preprocessors\n",
        "\n",
        "matplotlib.interactive(False)\n",
        "logging.basicConfig(format='%(asctime)s %(levelname)s %(name)s: %(message)s')\n",
        "\n",
        "\n",
        "class ImageReader:\n",
        "    \"\"\"Read image with cv2 from path and return image and label\"\"\"\n",
        "    def __init__(self, method: int = cv2.IMREAD_COLOR, log_level: int = logging.INFO) -> None:\n",
        "        self._method = method\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "        self.logger.setLevel(log_level)\n",
        "\n",
        "    def __call__(self, image_path: typing.Union[str, np.ndarray], label: typing.Any) -> typing.Tuple[Image, typing.Any]:\n",
        "        \"\"\" Read image with cv2 from path and return image and label\n",
        "        \n",
        "        Args:\n",
        "            image_path (typing.Union[str, np.ndarray]): Path to image or numpy array\n",
        "            label (Any): Label of image\n",
        "\n",
        "        Returns:\n",
        "            Image: Image object\n",
        "            Any: Label of image\n",
        "        \"\"\"\n",
        "        if isinstance(image_path, str):\n",
        "            # check whether image_path exists\n",
        "            if not os.path.exists(image_path):\n",
        "                raise FileNotFoundError(f\"Image {image_path} not found.\")\n",
        "        elif isinstance(image_path, np.ndarray):\n",
        "            pass\n",
        "        else:\n",
        "            raise TypeError(f\"Image {image_path} is not a string or numpy array.\")\n",
        "\n",
        "        image = Image(image = image_path, method = self._method)\n",
        "        if image.image is None:\n",
        "            image = None\n",
        "            self.logger.warning(f\"Image {image_path} could not be read, returning None.\")\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class WavReader:\n",
        "    \"\"\"Read wav file with librosa and return audio and label\n",
        "    \n",
        "    Attributes:\n",
        "        frame_length (int): Length of the frames in samples.\n",
        "        frame_step (int): Step size between frames in samples.\n",
        "        fft_length (int): Number of FFT components.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        frame_length: int=256, \n",
        "        frame_step: int=160,\n",
        "        fft_length: int=384,\n",
        "        *args, **kwargs\n",
        "        ) -> None:\n",
        "        self.frame_length = frame_length\n",
        "        self.frame_step = frame_step\n",
        "        self.fft_length = fft_length\n",
        "\n",
        "    @staticmethod\n",
        "    def get_spectrogram(wav_path: str, frame_length: int, frame_step: int, fft_length: int) -> np.ndarray:\n",
        "        \"\"\"Compute the spectrogram of a WAV file\n",
        "\n",
        "        Args:\n",
        "            wav_path (str): Path to the WAV file.\n",
        "            frame_length (int): Length of the frames in samples.\n",
        "            frame_step (int): Step size between frames in samples.\n",
        "            fft_length (int): Number of FFT components.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Spectrogram of the WAV file.\n",
        "        \"\"\"\n",
        "        # Load the wav file and store the audio data in the variable 'audio' and the sample rate in 'orig_sr'\n",
        "        audio, orig_sr = librosa.load(wav_path) \n",
        "\n",
        "        # Compute the Short Time Fourier Transform (STFT) of the audio data and store it in the variable 'spectrogram'\n",
        "        # The STFT is computed with a hop length of 'frame_step' samples, a window length of 'frame_length' samples, and 'fft_length' FFT components.\n",
        "        # The resulting spectrogram is also transposed for convenience\n",
        "        spectrogram = librosa.stft(audio, hop_length=frame_step, win_length=frame_length, n_fft=fft_length).T\n",
        "\n",
        "        # Take the absolute value of the spectrogram to obtain the magnitude spectrum\n",
        "        spectrogram = np.abs(spectrogram)\n",
        "\n",
        "        # Take the square root of the magnitude spectrum to obtain the log spectrogram\n",
        "        spectrogram = np.power(spectrogram, 0.5)\n",
        "\n",
        "        # Normalize the spectrogram by subtracting the mean and dividing by the standard deviation.\n",
        "        # A small value of 1e-10 is added to the denominator to prevent division by zero.\n",
        "        spectrogram = (spectrogram - np.mean(spectrogram)) / (np.std(spectrogram) + 1e-10)\n",
        "\n",
        "        return spectrogram\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_raw_audio(wav_path: str, title:str = None, sr: int = 16000) -> None:\n",
        "        \"\"\"Plot the raw audio of a WAV file\n",
        "\n",
        "        Args:\n",
        "            wav_path (str): Path to the WAV file.\n",
        "            sr (int, optional): Sample rate of the WAV file. Defaults to 16000.\n",
        "        \"\"\"\n",
        "        # Load the wav file and store the audio data in the variable 'audio' and the sample rate in 'orig_sr'\n",
        "        audio, orig_sr = librosa.load(wav_path, sr=sr)\n",
        "\n",
        "        duration = len(audio) / orig_sr\n",
        "\n",
        "        time = np.linspace(0, duration, num=len(audio))\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.plot(time, audio)\n",
        "        plt.title(title) if title else plt.title('Audio Plot')\n",
        "        plt.ylabel('signal wave')\n",
        "        plt.xlabel('time (s)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_spectrogram(spectrogram: np.ndarray, title:str = \"\", transpose: bool = True, invert: bool = True) -> None:\n",
        "        \"\"\"Plot the spectrogram of a WAV file\n",
        "\n",
        "        Args:\n",
        "            spectrogram (np.ndarray): Spectrogram of the WAV file.\n",
        "            title (str, optional): Title of the plot. Defaults to None.\n",
        "            transpose (bool, optional): Transpose the spectrogram. Defaults to True.\n",
        "            invert (bool, optional): Invert the spectrogram. Defaults to True.\n",
        "        \"\"\"\n",
        "        if transpose:\n",
        "            spectrogram = spectrogram.T\n",
        "        \n",
        "        if invert:\n",
        "            spectrogram = spectrogram[::-1]\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.imshow(spectrogram, aspect='auto', origin='lower')\n",
        "        plt.title(f'Spectrogram: {title}')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.colorbar()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def __call__(self, audio_path: str, label: typing.Any):\n",
        "        \"\"\"\n",
        "        Extract the spectrogram and label of a WAV file.\n",
        "\n",
        "        Args:\n",
        "            audio_path (str): Path to the WAV file.\n",
        "            label (typing.Any): Label of the WAV file.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.ndarray, typing.Any]: Spectrogram of the WAV file and its label.\n",
        "        \"\"\"\n",
        "        return self.get_spectrogram(audio_path, self.frame_length, self.frame_step, self.fft_length), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb7cR5TeSv_1"
      },
      "outputs": [],
      "source": [
        "#mltu tensorflow model_utils\n",
        "\n",
        "class CustomModel(Model):\n",
        "    \"\"\" Custom TensorFlow model for debugging training process purposes\n",
        "    \"\"\"\n",
        "    def train_step(self, train_data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        inputs, targets = train_data\n",
        "        with tf.GradientTape() as tape:\n",
        "            results = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, results, regularization_losses=self.losses)\n",
        "            gradients = tape.gradient(loss, self.trainable_weights)\n",
        "\n",
        "        # Applying the gradients on the model using the specified optimizer\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "\n",
        "        # Update the metrics.\n",
        "        # Metrics are configured in `compile()`.\n",
        "        self.compiled_metrics.update_state(targets, results)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, test_data):\n",
        "        inputs, targets = test_data\n",
        "        # Get prediction from model\n",
        "        results = self(inputs, training=False)\n",
        "\n",
        "        # Update the loss\n",
        "        self.compiled_loss(targets, results, regularization_losses=self.losses)\n",
        "\n",
        "        # Update the metrics\n",
        "        self.compiled_metrics.update_state(targets, results)\n",
        "\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "def activation_layer(layer, activation: str='relu', alpha: float=0.1) -> tf.Tensor:\n",
        "    \"\"\" Activation layer wrapper for LeakyReLU and ReLU activation functions\n",
        "    Args:\n",
        "        layer: tf.Tensor\n",
        "        activation: str, activation function name (default: 'relu')\n",
        "        alpha: float (LeakyReLU activation function parameter)\n",
        "    Returns:\n",
        "        tf.Tensor\n",
        "    \"\"\"\n",
        "    if activation == 'relu':\n",
        "        layer = layers.ReLU()(layer)\n",
        "    elif activation == 'leaky_relu':\n",
        "        layer = layers.LeakyReLU(alpha=alpha)(layer)\n",
        "\n",
        "    return layer\n",
        "\n",
        "def residual_block(\n",
        "    x: tf.Tensor,\n",
        "    filter_num: int,\n",
        "    strides: typing.Union[int, list]=2, \n",
        "    kernel_size: typing.Union[int, list]=3, \n",
        "    skip_conv: bool=True, \n",
        "    padding: str='same', \n",
        "    kernel_initializer: str='he_uniform', \n",
        "    activation: str='relu', \n",
        "    dropout: float=0.2\n",
        "    ):\n",
        "    # Create skip connection tensor\n",
        "    x_skip = x\n",
        "\n",
        "    # Perform 1-st convolution\n",
        "    x = layers.Conv2D(filter_num, kernel_size, padding = padding, strides = strides, kernel_initializer=kernel_initializer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = activation_layer(x, activation=activation)\n",
        "\n",
        "    # Perform 2-nd convoluti\n",
        "    x = layers.Conv2D(filter_num, kernel_size, padding = padding, kernel_initializer=kernel_initializer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # Perform 3-rd convolution if skip_conv is True, matchin the number of filters and the shape of the skip connection tensor\n",
        "    if skip_conv:\n",
        "        x_skip = layers.Conv2D(filter_num, 1, padding = padding, strides = strides, kernel_initializer=kernel_initializer)(x_skip)\n",
        "\n",
        "    # Add x and skip connection and apply activation function\n",
        "    x = layers.Add()([x, x_skip])     \n",
        "    x = activation_layer(x, activation=activation)\n",
        "\n",
        "    # Apply dropout\n",
        "    if dropout:\n",
        "        x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pLdSUjpe1iG"
      },
      "outputs": [],
      "source": [
        "#mltu Tensorflow losses\n",
        "\n",
        "class CTCloss(tf.keras.losses.Loss):\n",
        "    \"\"\" CTCLoss objec for training the model\"\"\"\n",
        "    def __init__(self, name: str = 'CTCloss') -> None:\n",
        "        super(CTCloss, self).__init__()\n",
        "        self.name = name\n",
        "        self.loss_fn = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def __call__(self, y_true: tf.Tensor, y_pred: tf.Tensor, sample_weight=None) -> tf.Tensor:\n",
        "        \"\"\" Compute the training batch CTC loss value\"\"\"\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc1OufiNfMJn"
      },
      "outputs": [],
      "source": [
        "#mltu.tensorflow.dataProvider\n",
        "class DataProvider(DataProvider, tf.keras.utils.Sequence):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCyP_HtJfL8O"
      },
      "outputs": [],
      "source": [
        "#mltu.tensorflow.callbacks\n",
        "\n",
        "class Model2onnx(Callback):\n",
        "    \"\"\" Converts the model to onnx format after training is finished. \"\"\"\n",
        "    def __init__(\n",
        "        self, \n",
        "        saved_model_path: str, \n",
        "        metadata: dict=None\n",
        "        ) -> None:\n",
        "        \"\"\" Converts the model to onnx format after training is finished.\n",
        "        Args:\n",
        "            saved_model_path (str): Path to the saved .h5 model.\n",
        "            metadata (dict, optional): Dictionary containing metadata to be added to the onnx model. Defaults to None.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.saved_model_path = saved_model_path\n",
        "        self.metadata = metadata\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.model.load_weights(self.saved_model_path)\n",
        "        self.onnx_model_path = self.saved_model_path.replace(\".h5\", \".onnx\")\n",
        "        tf2onnx.convert.from_keras(self.model, output_path=self.onnx_model_path)\n",
        "\n",
        "        if self.metadata and isinstance(self.metadata, dict):\n",
        "            # Load the ONNX model\n",
        "            onnx_model = onnx.load(self.onnx_model_path)\n",
        "\n",
        "            # Add the metadata dictionary to the model's metadata_props attribute\n",
        "            for key, value in self.metadata.items():\n",
        "                meta = onnx_model.metadata_props.add()\n",
        "                meta.key = key\n",
        "                meta.value = value\n",
        "\n",
        "            # Save the modified ONNX model\n",
        "            onnx.save(onnx_model, self.onnx_model_path)\n",
        "\n",
        "class TrainLogger(Callback):\n",
        "    \"\"\"Logs training metrics to a file.\n",
        "    \n",
        "    Args:\n",
        "        log_path (str): Path to the directory where the log file will be saved.\n",
        "        log_file (str, optional): Name of the log file. Defaults to 'logs.log'.\n",
        "        logLevel (int, optional): Logging level. Defaults to logging.INFO.\n",
        "    \"\"\"\n",
        "    def __init__(self, log_path: str, log_file: str='logs.log', logLevel=logging.INFO) -> None:\n",
        "        super().__init__()\n",
        "        self.log_path = log_path\n",
        "        self.log_file = log_file\n",
        "\n",
        "        if not os.path.exists(log_path):\n",
        "            os.mkdir(log_path)\n",
        "\n",
        "        self.logger = logging.getLogger()\n",
        "        self.logger.setLevel(logLevel)\n",
        "\n",
        "        self.formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "\n",
        "        self.file_handler = logging.FileHandler(os.path.join(self.log_path, self.log_file))\n",
        "        self.file_handler.setLevel(logLevel)\n",
        "        self.file_handler.setFormatter(self.formatter)\n",
        "\n",
        "        self.logger.addHandler(self.file_handler)\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs: dict=None):\n",
        "        epoch_message = f\"Epoch {epoch}; \"\n",
        "        logs_message = \"; \".join([f\"{key}: {value}\" for key, value in logs.items()])\n",
        "        self.logger.info(epoch_message + logs_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFWDo3yBfL0u"
      },
      "outputs": [],
      "source": [
        "#mltu.tensorflow.metrics\n",
        "\n",
        "class CWERMetric(tf.keras.metrics.Metric):\n",
        "    \"\"\"A custom TensorFlow metric to compute the Character Error Rate (CER).\n",
        "    \n",
        "    Args:\n",
        "        padding_token: An integer representing the padding token in the input data.\n",
        "        name: (Optional) string name of the metric instance.\n",
        "        **kwargs: Additional keyword arguments.\n",
        "    \"\"\"\n",
        "    def __init__(self, padding_token, name='CWER', **kwargs):\n",
        "        # Initialize the base Metric class\n",
        "        super(CWERMetric, self).__init__(name=name, **kwargs)\n",
        "        \n",
        "        # Initialize variables to keep track of the cumulative character/word error rates and counter\n",
        "        self.cer_accumulator = tf.Variable(0.0, name=\"cer_accumulator\", dtype=tf.float32)\n",
        "        self.wer_accumulator = tf.Variable(0.0, name=\"wer_accumulator\", dtype=tf.float32)\n",
        "        self.batch_counter = tf.Variable(0, name=\"batch_counter\", dtype=tf.int32)\n",
        "        \n",
        "        # Store the padding token as an attribute\n",
        "        self.padding_token = padding_token\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"Updates the state variables of the metric.\n",
        "\n",
        "        Args:\n",
        "            y_true: A tensor of true labels with shape (batch_size, sequence_length).\n",
        "            y_pred: A tensor of predicted labels with shape (batch_size, sequence_length, num_classes).\n",
        "            sample_weight: (Optional) a tensor of weights with shape (batch_size, sequence_length).\n",
        "        \"\"\"\n",
        "        # Get the input shape and length\n",
        "        input_shape = tf.keras.backend.shape(y_pred)\n",
        "        input_length = tf.ones(shape=input_shape[0], dtype='int32') * tf.cast(input_shape[1], 'int32')\n",
        "\n",
        "        # Decode the predicted labels using greedy decoding\n",
        "        decode_predicted, log = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=True)\n",
        "\n",
        "        # Convert the dense decode tensor to a sparse tensor\n",
        "        predicted_labels_sparse = tf.keras.backend.ctc_label_dense_to_sparse(decode_predicted[0], input_length)\n",
        "        \n",
        "        # Convert the dense true labels tensor to a sparse tensor and cast to int64\n",
        "        true_labels_sparse = tf.cast(tf.keras.backend.ctc_label_dense_to_sparse(y_true, input_length), \"int64\")\n",
        "\n",
        "        # Retain only the non-padding elements in the predicted labels tensor\n",
        "        predicted_labels_sparse = tf.sparse.retain(predicted_labels_sparse, tf.not_equal(predicted_labels_sparse.values, -1))\n",
        "        \n",
        "        # Retain only the non-padding elements in the true labels tensor\n",
        "        true_labels_sparse = tf.sparse.retain(true_labels_sparse, tf.not_equal(true_labels_sparse.values, self.padding_token))\n",
        "\n",
        "        # Calculate the normalized edit distance between the predicted labels and true labels tensors\n",
        "        distance = tf.edit_distance(predicted_labels_sparse, true_labels_sparse, normalize=True)\n",
        "\n",
        "        # Add the sum of the distance tensor to the cer_accumulator variable\n",
        "        self.cer_accumulator.assign_add(tf.reduce_sum(distance))\n",
        "        \n",
        "        # Increment the batch_counter by the batch size\n",
        "        self.batch_counter.assign_add(len(y_true))\n",
        "\n",
        "        # Calculate the number of wrong words in batch and add to wer_accumulator variable\n",
        "        self.wer_accumulator.assign_add(tf.reduce_sum(tf.cast(tf.not_equal(distance, 0), tf.float32)))\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"Computes and returns the metric result.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the CER and WER.\n",
        "        \"\"\"\n",
        "        return {\n",
        "                \"CER\": tf.math.divide_no_nan(self.cer_accumulator, tf.cast(self.batch_counter, tf.float32)),\n",
        "                \"WER\": tf.math.divide_no_nan(self.wer_accumulator, tf.cast(self.batch_counter, tf.float32))\n",
        "        }\n",
        "\n",
        "class CERMetric(tf.keras.metrics.Metric):\n",
        "    \"\"\"A custom TensorFlow metric to compute the Character Error Rate (CER).\n",
        "    \n",
        "    Args:\n",
        "        vocabulary: A string of the vocabulary used to encode the labels.\n",
        "        name: (Optional) string name of the metric instance.\n",
        "        **kwargs: Additional keyword arguments.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocabulary, name='CER', **kwargs):\n",
        "        # Initialize the base Metric class\n",
        "        super(CERMetric, self).__init__(name=name, **kwargs)\n",
        "        \n",
        "        # Initialize variables to keep track of the cumulative character/word error rates and counter\n",
        "        self.cer_accumulator = tf.Variable(0.0, name=\"cer_accumulator\", dtype=tf.float32)\n",
        "        self.batch_counter = tf.Variable(0, name=\"batch_counter\", dtype=tf.int32)\n",
        "        \n",
        "        # Store the vocabulary as an attribute\n",
        "        self.vocabulary = tf.constant(list(vocabulary))\n",
        "\n",
        "    @staticmethod\n",
        "    def get_cer(pred_decoded, y_true, vocab, padding=-1):\n",
        "        \"\"\" Calculates the character error rate (CER) between the predicted labels and true labels for a batch of input data.\n",
        "\n",
        "        Args:\n",
        "            pred_decoded (tf.Tensor): The predicted labels, with dtype=tf.int32, usually output from tf.keras.backend.ctc_decode\n",
        "            y_true (tf.Tensor): The true labels, with dtype=tf.int32\n",
        "            vocab (tf.Tensor): The vocabulary tensor, with dtype=tf.string\n",
        "            padding (int, optional): The padding token when converting to sparse tensor. Defaults to -1.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The CER between the predicted labels and true labels\n",
        "        \"\"\"\n",
        "        # Keep only valid indices in the predicted labels tensor, replacing invalid indices with padding token\n",
        "        vocab_length = tf.cast(tf.shape(vocab)[0], tf.int64)\n",
        "        valid_pred_indices = tf.less(pred_decoded, vocab_length)\n",
        "        valid_pred = tf.where(valid_pred_indices, pred_decoded, padding)\n",
        "\n",
        "        # Keep only valid indices in the true labels tensor, replacing invalid indices with padding token\n",
        "        y_true = tf.cast(y_true, tf.int64)\n",
        "        valid_true_indices = tf.less(y_true, vocab_length)\n",
        "        valid_true = tf.where(valid_true_indices, y_true, padding)\n",
        "\n",
        "        # Convert the valid predicted labels tensor to a sparse tensor\n",
        "        sparse_pred = tf.RaggedTensor.from_tensor(valid_pred, padding=padding).to_sparse()\n",
        "\n",
        "        # Convert the valid true labels tensor to a sparse tensor\n",
        "        sparse_true = tf.RaggedTensor.from_tensor(valid_true, padding=padding).to_sparse()\n",
        "\n",
        "        # Calculate the normalized edit distance between the sparse predicted labels tensor and sparse true labels tensor\n",
        "        distance = tf.edit_distance(sparse_pred, sparse_true, normalize=True)\n",
        "\n",
        "        return distance\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"Updates the state variables of the metric.\n",
        "\n",
        "        Args:\n",
        "            y_true: A tensor of true labels with shape (batch_size, sequence_length).\n",
        "            y_pred: A tensor of predicted labels with shape (batch_size, sequence_length, num_classes).\n",
        "            sample_weight: (Optional) a tensor of weights with shape (batch_size, sequence_length).\n",
        "        \"\"\"\n",
        "        # Get the input shape and length\n",
        "        input_shape = tf.keras.backend.shape(y_pred)\n",
        "        input_length = tf.ones(shape=input_shape[0], dtype='int32') * tf.cast(input_shape[1], 'int32')\n",
        "\n",
        "        # Decode the predicted labels using greedy decoding\n",
        "        decode_predicted, log = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=True)\n",
        "\n",
        "        # Calculate the normalized edit distance between the predicted labels and true labels tensors\n",
        "        distance = self.get_cer(decode_predicted[0], y_true, self.vocabulary)\n",
        "\n",
        "        # Add the sum of the distance tensor to the cer_accumulator variable\n",
        "        self.cer_accumulator.assign_add(tf.reduce_sum(distance))\n",
        "        \n",
        "        # Increment the batch_counter by the batch size\n",
        "        self.batch_counter.assign_add(len(y_true))\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\" Computes and returns the metric result.\n",
        "\n",
        "        Returns:\n",
        "            A TensorFlow float representing the CER (character error rate).\n",
        "        \"\"\"\n",
        "        return tf.math.divide_no_nan(self.cer_accumulator, tf.cast(self.batch_counter, tf.float32))\n",
        "\n",
        "\n",
        "class WERMetric(tf.keras.metrics.Metric):\n",
        "    \"\"\"A custom TensorFlow metric to compute the Word Error Rate (WER).\n",
        "    \n",
        "    Attributes:\n",
        "        vocabulary: A string of the vocabulary used to encode the labels.\n",
        "        name: (Optional) string name of the metric instance.\n",
        "        **kwargs: Additional keyword arguments.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocabulary: str, name='WER', **kwargs):\n",
        "        # Initialize the base Metric class\n",
        "        super(WERMetric, self).__init__(name=name, **kwargs)\n",
        "        \n",
        "        # Initialize variables to keep track of the cumulative character/word error rates and counter\n",
        "        self.wer_accumulator = tf.Variable(0.0, name=\"wer_accumulator\", dtype=tf.float32)\n",
        "        self.batch_counter = tf.Variable(0, name=\"batch_counter\", dtype=tf.int32)\n",
        "        \n",
        "        # Store the vocabulary as an attribute\n",
        "        self.vocabulary = tf.constant(list(vocabulary))\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_dense(dense_input: tf.Tensor, vocab: tf.Tensor, padding=-1) -> tf.SparseTensor:\n",
        "        \"\"\" Preprocess the dense input tensor to a sparse tensor with given vocabulary\n",
        "        \n",
        "        Args:\n",
        "            dense_input (tf.Tensor): The dense input tensor, dtype=tf.int32\n",
        "            vocab (tf.Tensor): The vocabulary tensor, dtype=tf.string\n",
        "            padding (int, optional): The padding token when converting to sparse tensor. Defaults to -1.\n",
        "\n",
        "        Returns:\n",
        "            tf.SparseTensor: The sparse tensor with given vocabulary\n",
        "        \"\"\"\n",
        "        # Keep only the valid indices of the dense input tensor\n",
        "        vocab_length = tf.cast(tf.shape(vocab)[0], tf.int64)\n",
        "        dense_input = tf.cast(dense_input, tf.int64)\n",
        "        valid_indices = tf.less(dense_input, vocab_length)\n",
        "        valid_input = tf.where(valid_indices, dense_input, padding)\n",
        "\n",
        "        # Convert the valid input tensor to a ragged tensor with padding\n",
        "        input_ragged = tf.RaggedTensor.from_tensor(valid_input, padding=padding)\n",
        "\n",
        "        # Use the vocabulary tensor to get the strings corresponding to the indices in the ragged tensor\n",
        "        input_binary_chars = tf.gather(vocab, input_ragged)\n",
        "\n",
        "        # Join the binary character tensor along the sequence axis to get the input strings\n",
        "        input_strings = tf.strings.reduce_join(input_binary_chars, axis=1, separator='')\n",
        "\n",
        "        # Convert the input strings tensor to a sparse tensor\n",
        "        input_sparse_string = tf.strings.split(input_strings, sep=' ').to_sparse()\n",
        "\n",
        "        return input_sparse_string\n",
        "\n",
        "    @staticmethod\n",
        "    def get_wer(pred_decoded, y_true, vocab, padding=-1):\n",
        "        \"\"\" Calculate the normalized WER distance between the predicted labels and true labels tensors\n",
        "\n",
        "        Args:\n",
        "            pred_decoded (tf.Tensor): The predicted labels tensor, dtype=tf.int32. Usually output from tf.keras.backend.ctc_decode\n",
        "            y_true (tf.Tensor): The true labels tensor, dtype=tf.int32\n",
        "            vocab (tf.Tensor): The vocabulary tensor, dtype=tf.string\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor: The normalized WER distance between the predicted labels and true labels tensors\n",
        "        \"\"\"\n",
        "        pred_sparse = WERMetric.preprocess_dense(pred_decoded, vocab, padding=padding)\n",
        "        true_sparse = WERMetric.preprocess_dense(y_true, vocab, padding=padding)\n",
        "\n",
        "        distance = tf.edit_distance(pred_sparse, true_sparse, normalize=True)\n",
        "\n",
        "        return distance\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # Get the input shape and length\n",
        "        input_shape = tf.keras.backend.shape(y_pred)\n",
        "        input_length = tf.ones(shape=input_shape[0], dtype='int32') * tf.cast(input_shape[1], 'int32')\n",
        "\n",
        "        # Decode the predicted labels using greedy decoding\n",
        "        decode_predicted, log = tf.keras.backend.ctc_decode(y_pred, input_length, greedy=True)\n",
        "\n",
        "        # Calculate the normalized edit distance between the predicted labels and true labels tensors\n",
        "        distance = self.get_wer(decode_predicted[0], y_true, self.vocabulary)\n",
        "\n",
        "        # Calculate the number of wrong words in batch and add to wer_accumulator variable\n",
        "        self.wer_accumulator.assign_add(tf.reduce_sum(tf.cast(distance, tf.float32)))\n",
        "\n",
        "        # Increment the batch_counter by the batch size\n",
        "        self.batch_counter.assign_add(len(y_true))\n",
        "\n",
        "    def result(self):\n",
        "        \"\"\"Computes and returns the metric result.\n",
        "\n",
        "        Returns:\n",
        "            A TensorFlow float representing the WER (Word Error Rate).\n",
        "        \"\"\"\n",
        "        return tf.math.divide_no_nan(self.wer_accumulator, tf.cast(self.batch_counter, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l6wnMtDSv8T"
      },
      "outputs": [],
      "source": [
        "#model.py\n",
        "\n",
        "def train_model(input_dim, output_dim, activation='leaky_relu', dropout=0.2):\n",
        "    \n",
        "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
        "\n",
        "    # normalize images here instead in preprocessing step\n",
        "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
        "\n",
        "    x1 = residual_block(input, 16, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
        "\n",
        "    x2 = residual_block(x1, 16, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x3 = residual_block(x2, 16, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    x4 = residual_block(x3, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x5 = residual_block(x4, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    x6 = residual_block(x5, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x7 = residual_block(x6, 32, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
        "\n",
        "    x8 = residual_block(x7, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
        "    x9 = residual_block(x8, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
        "\n",
        "    squeezed = layers.Reshape((x9.shape[-3] * x9.shape[-2], x9.shape[-1]))(x9)\n",
        "\n",
        "    blstm = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(squeezed)\n",
        "    blstm = layers.Dropout(dropout)(blstm)\n",
        "\n",
        "    output = layers.Dense(output_dim + 1, activation='softmax', name=\"output\")(blstm)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncslWhCqRHmY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_UZ1Cr5LVe4",
        "outputId": "0bb9aea8-bf00-4b22-97d9-fd3c2a92d009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:DataProvider:Skipping Dataset validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "______________________________________________________________________________________________________________\n",
            " Layer (type)                       Output Shape            Param #      Connected to                         \n",
            "==============================================================================================================\n",
            " input (InputLayer)                 [(None, 50, 200, 3)]    0            []                                   \n",
            "                                                                                                              \n",
            " lambda (Lambda)                    (None, 50, 200, 3)      0            ['input[0][0]']                      \n",
            "                                                                                                              \n",
            " conv2d (Conv2D)                    (None, 50, 200, 16)     448          ['lambda[0][0]']                     \n",
            "                                                                                                              \n",
            " batch_normalization (BatchNormaliz  (None, 50, 200, 16)    64           ['conv2d[0][0]']                     \n",
            " ation)                                                                                                       \n",
            "                                                                                                              \n",
            " leaky_re_lu (LeakyReLU)            (None, 50, 200, 16)     0            ['batch_normalization[0][0]']        \n",
            "                                                                                                              \n",
            " conv2d_1 (Conv2D)                  (None, 50, 200, 16)     2320         ['leaky_re_lu[0][0]']                \n",
            "                                                                                                              \n",
            " batch_normalization_1 (BatchNormal  (None, 50, 200, 16)    64           ['conv2d_1[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " conv2d_2 (Conv2D)                  (None, 50, 200, 16)     64           ['lambda[0][0]']                     \n",
            "                                                                                                              \n",
            " add (Add)                          (None, 50, 200, 16)     0            ['batch_normalization_1[0][0]',      \n",
            "                                                                          'conv2d_2[0][0]']                   \n",
            "                                                                                                              \n",
            " leaky_re_lu_1 (LeakyReLU)          (None, 50, 200, 16)     0            ['add[0][0]']                        \n",
            "                                                                                                              \n",
            " dropout (Dropout)                  (None, 50, 200, 16)     0            ['leaky_re_lu_1[0][0]']              \n",
            "                                                                                                              \n",
            " conv2d_3 (Conv2D)                  (None, 25, 100, 16)     2320         ['dropout[0][0]']                    \n",
            "                                                                                                              \n",
            " batch_normalization_2 (BatchNormal  (None, 25, 100, 16)    64           ['conv2d_3[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " leaky_re_lu_2 (LeakyReLU)          (None, 25, 100, 16)     0            ['batch_normalization_2[0][0]']      \n",
            "                                                                                                              \n",
            " conv2d_4 (Conv2D)                  (None, 25, 100, 16)     2320         ['leaky_re_lu_2[0][0]']              \n",
            "                                                                                                              \n",
            " batch_normalization_3 (BatchNormal  (None, 25, 100, 16)    64           ['conv2d_4[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " conv2d_5 (Conv2D)                  (None, 25, 100, 16)     272          ['dropout[0][0]']                    \n",
            "                                                                                                              \n",
            " add_1 (Add)                        (None, 25, 100, 16)     0            ['batch_normalization_3[0][0]',      \n",
            "                                                                          'conv2d_5[0][0]']                   \n",
            "                                                                                                              \n",
            " leaky_re_lu_3 (LeakyReLU)          (None, 25, 100, 16)     0            ['add_1[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_1 (Dropout)                (None, 25, 100, 16)     0            ['leaky_re_lu_3[0][0]']              \n",
            "                                                                                                              \n",
            " conv2d_6 (Conv2D)                  (None, 25, 100, 16)     2320         ['dropout_1[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_4 (BatchNormal  (None, 25, 100, 16)    64           ['conv2d_6[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " leaky_re_lu_4 (LeakyReLU)          (None, 25, 100, 16)     0            ['batch_normalization_4[0][0]']      \n",
            "                                                                                                              \n",
            " conv2d_7 (Conv2D)                  (None, 25, 100, 16)     2320         ['leaky_re_lu_4[0][0]']              \n",
            "                                                                                                              \n",
            " batch_normalization_5 (BatchNormal  (None, 25, 100, 16)    64           ['conv2d_7[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " add_2 (Add)                        (None, 25, 100, 16)     0            ['batch_normalization_5[0][0]',      \n",
            "                                                                          'dropout_1[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_5 (LeakyReLU)          (None, 25, 100, 16)     0            ['add_2[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_2 (Dropout)                (None, 25, 100, 16)     0            ['leaky_re_lu_5[0][0]']              \n",
            "                                                                                                              \n",
            " conv2d_8 (Conv2D)                  (None, 13, 50, 32)      4640         ['dropout_2[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_6 (BatchNormal  (None, 13, 50, 32)     128          ['conv2d_8[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " leaky_re_lu_6 (LeakyReLU)          (None, 13, 50, 32)      0            ['batch_normalization_6[0][0]']      \n",
            "                                                                                                              \n",
            " conv2d_9 (Conv2D)                  (None, 13, 50, 32)      9248         ['leaky_re_lu_6[0][0]']              \n",
            "                                                                                                              \n",
            " batch_normalization_7 (BatchNormal  (None, 13, 50, 32)     128          ['conv2d_9[0][0]']                   \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " conv2d_10 (Conv2D)                 (None, 13, 50, 32)      544          ['dropout_2[0][0]']                  \n",
            "                                                                                                              \n",
            " add_3 (Add)                        (None, 13, 50, 32)      0            ['batch_normalization_7[0][0]',      \n",
            "                                                                          'conv2d_10[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_7 (LeakyReLU)          (None, 13, 50, 32)      0            ['add_3[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_3 (Dropout)                (None, 13, 50, 32)      0            ['leaky_re_lu_7[0][0]']              \n",
            "                                                                                                              \n",
            " conv2d_11 (Conv2D)                 (None, 13, 50, 32)      9248         ['dropout_3[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_8 (BatchNormal  (None, 13, 50, 32)     128          ['conv2d_11[0][0]']                  \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " leaky_re_lu_8 (LeakyReLU)          (None, 13, 50, 32)      0            ['batch_normalization_8[0][0]']      \n",
            "                                                                                                              \n",
            " conv2d_12 (Conv2D)                 (None, 13, 50, 32)      9248         ['leaky_re_lu_8[0][0]']              \n",
            "                                                                                                              \n",
            " batch_normalization_9 (BatchNormal  (None, 13, 50, 32)     128          ['conv2d_12[0][0]']                  \n",
            " ization)                                                                                                     \n",
            "                                                                                                              \n",
            " add_4 (Add)                        (None, 13, 50, 32)      0            ['batch_normalization_9[0][0]',      \n",
            "                                                                          'dropout_3[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_9 (LeakyReLU)          (None, 13, 50, 32)      0            ['add_4[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_4 (Dropout)                (None, 13, 50, 32)      0            ['leaky_re_lu_9[0][0]']              \n",
            "                                                                                                              \n",
            " conv2d_13 (Conv2D)                 (None, 7, 25, 64)       18496        ['dropout_4[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_10 (BatchNorma  (None, 7, 25, 64)      256          ['conv2d_13[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " leaky_re_lu_10 (LeakyReLU)         (None, 7, 25, 64)       0            ['batch_normalization_10[0][0]']     \n",
            "                                                                                                              \n",
            " conv2d_14 (Conv2D)                 (None, 7, 25, 64)       36928        ['leaky_re_lu_10[0][0]']             \n",
            "                                                                                                              \n",
            " batch_normalization_11 (BatchNorma  (None, 7, 25, 64)      256          ['conv2d_14[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " conv2d_15 (Conv2D)                 (None, 7, 25, 64)       2112         ['dropout_4[0][0]']                  \n",
            "                                                                                                              \n",
            " add_5 (Add)                        (None, 7, 25, 64)       0            ['batch_normalization_11[0][0]',     \n",
            "                                                                          'conv2d_15[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_11 (LeakyReLU)         (None, 7, 25, 64)       0            ['add_5[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_5 (Dropout)                (None, 7, 25, 64)       0            ['leaky_re_lu_11[0][0]']             \n",
            "                                                                                                              \n",
            " conv2d_16 (Conv2D)                 (None, 7, 25, 32)       18464        ['dropout_5[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_12 (BatchNorma  (None, 7, 25, 32)      128          ['conv2d_16[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " leaky_re_lu_12 (LeakyReLU)         (None, 7, 25, 32)       0            ['batch_normalization_12[0][0]']     \n",
            "                                                                                                              \n",
            " conv2d_17 (Conv2D)                 (None, 7, 25, 32)       9248         ['leaky_re_lu_12[0][0]']             \n",
            "                                                                                                              \n",
            " batch_normalization_13 (BatchNorma  (None, 7, 25, 32)      128          ['conv2d_17[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " conv2d_18 (Conv2D)                 (None, 7, 25, 32)       2080         ['dropout_5[0][0]']                  \n",
            "                                                                                                              \n",
            " add_6 (Add)                        (None, 7, 25, 32)       0            ['batch_normalization_13[0][0]',     \n",
            "                                                                          'conv2d_18[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_13 (LeakyReLU)         (None, 7, 25, 32)       0            ['add_6[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_6 (Dropout)                (None, 7, 25, 32)       0            ['leaky_re_lu_13[0][0]']             \n",
            "                                                                                                              \n",
            " conv2d_19 (Conv2D)                 (None, 4, 13, 64)       18496        ['dropout_6[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_14 (BatchNorma  (None, 4, 13, 64)      256          ['conv2d_19[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " leaky_re_lu_14 (LeakyReLU)         (None, 4, 13, 64)       0            ['batch_normalization_14[0][0]']     \n",
            "                                                                                                              \n",
            " conv2d_20 (Conv2D)                 (None, 4, 13, 64)       36928        ['leaky_re_lu_14[0][0]']             \n",
            "                                                                                                              \n",
            " batch_normalization_15 (BatchNorma  (None, 4, 13, 64)      256          ['conv2d_20[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " conv2d_21 (Conv2D)                 (None, 4, 13, 64)       2112         ['dropout_6[0][0]']                  \n",
            "                                                                                                              \n",
            " add_7 (Add)                        (None, 4, 13, 64)       0            ['batch_normalization_15[0][0]',     \n",
            "                                                                          'conv2d_21[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_15 (LeakyReLU)         (None, 4, 13, 64)       0            ['add_7[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_7 (Dropout)                (None, 4, 13, 64)       0            ['leaky_re_lu_15[0][0]']             \n",
            "                                                                                                              \n",
            " conv2d_22 (Conv2D)                 (None, 4, 13, 64)       36928        ['dropout_7[0][0]']                  \n",
            "                                                                                                              \n",
            " batch_normalization_16 (BatchNorma  (None, 4, 13, 64)      256          ['conv2d_22[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " leaky_re_lu_16 (LeakyReLU)         (None, 4, 13, 64)       0            ['batch_normalization_16[0][0]']     \n",
            "                                                                                                              \n",
            " conv2d_23 (Conv2D)                 (None, 4, 13, 64)       36928        ['leaky_re_lu_16[0][0]']             \n",
            "                                                                                                              \n",
            " batch_normalization_17 (BatchNorma  (None, 4, 13, 64)      256          ['conv2d_23[0][0]']                  \n",
            " lization)                                                                                                    \n",
            "                                                                                                              \n",
            " add_8 (Add)                        (None, 4, 13, 64)       0            ['batch_normalization_17[0][0]',     \n",
            "                                                                          'dropout_7[0][0]']                  \n",
            "                                                                                                              \n",
            " leaky_re_lu_17 (LeakyReLU)         (None, 4, 13, 64)       0            ['add_8[0][0]']                      \n",
            "                                                                                                              \n",
            " dropout_8 (Dropout)                (None, 4, 13, 64)       0            ['leaky_re_lu_17[0][0]']             \n",
            "                                                                                                              \n",
            " reshape (Reshape)                  (None, 52, 64)          0            ['dropout_8[0][0]']                  \n",
            "                                                                                                              \n",
            " bidirectional (Bidirectional)      (None, 52, 256)         197632       ['reshape[0][0]']                    \n",
            "                                                                                                              \n",
            " dropout_9 (Dropout)                (None, 52, 256)         0            ['bidirectional[0][0]']              \n",
            "                                                                                                              \n",
            " output (Dense)                     (None, 52, 20)          5140         ['dropout_9[0][0]']                  \n",
            "                                                                                                              \n",
            "==============================================================================================================\n",
            "Total params: 469,492\n",
            "Trainable params: 468,148\n",
            "Non-trainable params: 1,344\n",
            "______________________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e745a064ece2>:232: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if not isinstance(annotation, (np.ndarray, int, float, str, np.uint8, np.float)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 37.5216 - CER: 3.0113 - WER: 1.0000\n",
            "Epoch 1: val_CER improved from inf to 1.00000, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 0; loss: 37.52164840698242; CER: 1.682905912399292; WER: 1.0; val_loss: 18.312543869018555; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 52s 495ms/step - loss: 37.5216 - CER: 2.9283 - WER: 1.0000 - val_loss: 18.3125 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 17.4762 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 2: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 1; loss: 17.476160049438477; CER: 1.0; WER: 1.0; val_loss: 16.66668128967285; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 17.4762 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.6667 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.5232 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 3: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 2; loss: 16.52324676513672; CER: 1.0; WER: 1.0; val_loss: 17.644847869873047; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 181ms/step - loss: 16.5232 - CER: 1.0000 - WER: 1.0000 - val_loss: 17.6448 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3867 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 4: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 3; loss: 16.38668441772461; CER: 1.0; WER: 1.0; val_loss: 16.854774475097656; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 225ms/step - loss: 16.3867 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.8548 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3431 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 5: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 4; loss: 16.34309959411621; CER: 1.0; WER: 1.0; val_loss: 16.822166442871094; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 183ms/step - loss: 16.3431 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.8222 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3344 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 6: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 5; loss: 16.334428787231445; CER: 1.0; WER: 1.0; val_loss: 16.37788200378418; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 16.3344 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3779 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3341 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 7: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 6; loss: 16.334064483642578; CER: 1.0; WER: 1.0; val_loss: 16.281295776367188; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 244ms/step - loss: 16.3341 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2813 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3356 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 8: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 7; loss: 16.33562660217285; CER: 1.0; WER: 1.0; val_loss: 16.253047943115234; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 183ms/step - loss: 16.3356 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2530 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3303 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 9: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 8; loss: 16.33027458190918; CER: 1.0; WER: 1.0; val_loss: 16.269086837768555; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 187ms/step - loss: 16.3303 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2691 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3250 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 10: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 9; loss: 16.324983596801758; CER: 1.0; WER: 1.0; val_loss: 16.285633087158203; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 213ms/step - loss: 16.3250 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2856 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3217 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 11: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 10; loss: 16.321727752685547; CER: 1.0; WER: 1.0; val_loss: 16.29184341430664; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 183ms/step - loss: 16.3217 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2918 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2922 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 12: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 11; loss: 16.29217529296875; CER: 1.0; WER: 1.0; val_loss: 16.308025360107422; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 248ms/step - loss: 16.2922 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3080 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3217 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 13: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 12; loss: 16.32174301147461; CER: 1.0; WER: 1.0; val_loss: 16.344030380249023; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 16.3217 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3440 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3148 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 14: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 13; loss: 16.314786911010742; CER: 1.0; WER: 1.0; val_loss: 16.29965591430664; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 203ms/step - loss: 16.3148 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2997 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3027 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 15: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 14; loss: 16.302709579467773; CER: 1.0; WER: 1.0; val_loss: 16.345285415649414; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 263ms/step - loss: 16.3027 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3453 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3091 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 16: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 15; loss: 16.309125900268555; CER: 1.0; WER: 1.0; val_loss: 16.299449920654297; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 16.3091 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2994 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3116 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 17: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 16; loss: 16.31155014038086; CER: 1.0; WER: 1.0; val_loss: 16.307891845703125; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 16.3116 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3079 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.3020 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 18: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 17; loss: 16.302000045776367; CER: 1.0; WER: 1.0; val_loss: 16.34222412109375; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 397ms/step - loss: 16.3020 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3422 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2925 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 19: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 18; loss: 16.292469024658203; CER: 1.0; WER: 1.0; val_loss: 16.325422286987305; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 16.2925 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3254 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2979 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 20: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 19; loss: 16.29793930053711; CER: 1.0; WER: 1.0; val_loss: 16.317594528198242; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 284ms/step - loss: 16.2979 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3176 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2785 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 21: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 20; loss: 16.278461456298828; CER: 1.0; WER: 1.0; val_loss: 16.328004837036133; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "15/15 [==============================] - 4s 201ms/step - loss: 16.2785 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3280 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2759 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 22: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 21; loss: 16.275917053222656; CER: 1.0; WER: 1.0; val_loss: 16.267778396606445; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 16.2759 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2678 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 23/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2819 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 23: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 22; loss: 16.281949996948242; CER: 1.0; WER: 1.0; val_loss: 16.27471351623535; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 267ms/step - loss: 16.2819 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2747 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 24/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2477 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 24: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 23; loss: 16.247709274291992; CER: 1.0; WER: 1.0; val_loss: 16.29003143310547; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 16.2477 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2900 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 25/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2441 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 25: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 24; loss: 16.24407958984375; CER: 1.0; WER: 1.0; val_loss: 16.325658798217773; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 197ms/step - loss: 16.2441 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.3257 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 26/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.2187 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 26: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 25; loss: 16.21873664855957; CER: 1.0; WER: 1.0; val_loss: 16.28009033203125; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 16.2187 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2801 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 27/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.1991 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 27: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 26; loss: 16.19913101196289; CER: 1.0; WER: 1.0; val_loss: 16.2260684967041; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 16.1991 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.2261 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 28/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.1466 - CER: 1.0000 - WER: 1.0000\n",
            "Epoch 28: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 27; loss: 16.146629333496094; CER: 1.0; WER: 1.0; val_loss: 16.11250114440918; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 197ms/step - loss: 16.1466 - CER: 1.0000 - WER: 1.0000 - val_loss: 16.1125 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 29/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.1083 - CER: 0.9998 - WER: 1.0000\n",
            "Epoch 29: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 28; loss: 16.108274459838867; CER: 0.9997863173484802; WER: 1.0; val_loss: 16.042821884155273; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 246ms/step - loss: 16.1083 - CER: 0.9998 - WER: 1.0000 - val_loss: 16.0428 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 30/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 16.0422 - CER: 0.9990 - WER: 1.0000\n",
            "Epoch 30: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 29; loss: 16.04220199584961; CER: 0.9970085024833679; WER: 1.0; val_loss: 15.83529281616211; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 16.0422 - CER: 0.9989 - WER: 1.0000 - val_loss: 15.8353 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 31/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.9986 - CER: 0.9912 - WER: 1.0000\n",
            "Epoch 31: val_CER did not improve from 1.00000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 30; loss: 15.998584747314453; CER: 0.9935897588729858; WER: 1.0; val_loss: 15.677528381347656; val_CER: 1.0; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 196ms/step - loss: 15.9986 - CER: 0.9913 - WER: 1.0000 - val_loss: 15.6775 - val_CER: 1.0000 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 32/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.8574 - CER: 0.9898 - WER: 1.0000\n",
            "Epoch 32: val_CER improved from 1.00000 to 0.96346, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 31; loss: 15.857357025146484; CER: 0.9863247871398926; WER: 1.0; val_loss: 15.567089080810547; val_CER: 0.9634615182876587; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 232ms/step - loss: 15.8574 - CER: 0.9896 - WER: 1.0000 - val_loss: 15.5671 - val_CER: 0.9635 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 33/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.7994 - CER: 0.9796 - WER: 1.0000\n",
            "Epoch 33: val_CER did not improve from 0.96346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 32; loss: 15.799398422241211; CER: 0.9811965227127075; WER: 1.0; val_loss: 15.388628005981445; val_CER: 0.9807692170143127; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 15.7994 - CER: 0.9797 - WER: 1.0000 - val_loss: 15.3886 - val_CER: 0.9808 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 34/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.6731 - CER: 0.9820 - WER: 1.0000\n",
            "Epoch 34: val_CER improved from 0.96346 to 0.95577, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 33; loss: 15.673070907592773; CER: 0.9805556535720825; WER: 1.0; val_loss: 15.186145782470703; val_CER: 0.9557691812515259; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 199ms/step - loss: 15.6731 - CER: 0.9819 - WER: 1.0000 - val_loss: 15.1861 - val_CER: 0.9558 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 35/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.5973 - CER: 0.9706 - WER: 1.0000\n",
            "Epoch 35: val_CER improved from 0.95577 to 0.94038, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 34; loss: 15.597277641296387; CER: 0.968589723110199; WER: 1.0; val_loss: 14.909214973449707; val_CER: 0.9403846263885498; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 15.5973 - CER: 0.9705 - WER: 1.0000 - val_loss: 14.9092 - val_CER: 0.9404 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 36/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.4760 - CER: 0.9693 - WER: 1.0000\n",
            "Epoch 36: val_CER improved from 0.94038 to 0.93077, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 35; loss: 15.476006507873535; CER: 0.9690171480178833; WER: 1.0; val_loss: 14.726493835449219; val_CER: 0.9307692050933838; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 202ms/step - loss: 15.4760 - CER: 0.9693 - WER: 1.0000 - val_loss: 14.7265 - val_CER: 0.9308 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 37/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.3922 - CER: 0.9553 - WER: 1.0000\n",
            "Epoch 37: val_CER improved from 0.93077 to 0.90577, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 36; loss: 15.392152786254883; CER: 0.9587606191635132; WER: 1.0; val_loss: 14.780749320983887; val_CER: 0.9057692289352417; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 201ms/step - loss: 15.3922 - CER: 0.9556 - WER: 1.0000 - val_loss: 14.7807 - val_CER: 0.9058 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 38/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.2343 - CER: 0.9404 - WER: 1.0000\n",
            "Epoch 38: val_CER did not improve from 0.90577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 37; loss: 15.234336853027344; CER: 0.9461537599563599; WER: 1.0; val_loss: 14.607556343078613; val_CER: 0.9134615659713745; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 196ms/step - loss: 15.2343 - CER: 0.9407 - WER: 1.0000 - val_loss: 14.6076 - val_CER: 0.9135 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 39/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 15.0126 - CER: 0.9482 - WER: 1.0000\n",
            "Epoch 39: val_CER did not improve from 0.90577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 38; loss: 15.012598991394043; CER: 0.9420939683914185; WER: 1.0; val_loss: 14.166898727416992; val_CER: 0.9115384817123413; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 15.0126 - CER: 0.9478 - WER: 1.0000 - val_loss: 14.1669 - val_CER: 0.9115 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 40/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.9112 - CER: 0.9332 - WER: 1.0000\n",
            "Epoch 40: val_CER did not improve from 0.90577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 39; loss: 14.911198616027832; CER: 0.9352563619613647; WER: 1.0; val_loss: 14.459461212158203; val_CER: 0.9134615659713745; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 197ms/step - loss: 14.9112 - CER: 0.9333 - WER: 1.0000 - val_loss: 14.4595 - val_CER: 0.9135 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 41/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.7728 - CER: 0.9314 - WER: 1.0000\n",
            "Epoch 41: val_CER did not improve from 0.90577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 40; loss: 14.772820472717285; CER: 0.9324786067008972; WER: 1.0; val_loss: 13.999755859375; val_CER: 0.9096153974533081; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 14.7728 - CER: 0.9315 - WER: 1.0000 - val_loss: 13.9998 - val_CER: 0.9096 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 42/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.6007 - CER: 0.9183 - WER: 1.0000\n",
            "Epoch 42: val_CER improved from 0.90577 to 0.87885, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 41; loss: 14.600720405578613; CER: 0.9136751890182495; WER: 1.0; val_loss: 13.335789680480957; val_CER: 0.8788461685180664; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 209ms/step - loss: 14.6007 - CER: 0.9180 - WER: 1.0000 - val_loss: 13.3358 - val_CER: 0.8788 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 43/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.5251 - CER: 0.9281 - WER: 1.0000\n",
            "Epoch 43: val_CER improved from 0.87885 to 0.87115, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 42; loss: 14.52509593963623; CER: 0.9190170168876648; WER: 1.0; val_loss: 13.288110733032227; val_CER: 0.8711538910865784; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 14.5251 - CER: 0.9276 - WER: 1.0000 - val_loss: 13.2881 - val_CER: 0.8712 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 44/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.1854 - CER: 0.8962 - WER: 1.0000\n",
            "Epoch 44: val_CER improved from 0.87115 to 0.85385, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 43; loss: 14.18542766571045; CER: 0.8886752724647522; WER: 1.0; val_loss: 13.25389289855957; val_CER: 0.8538461923599243; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 278ms/step - loss: 14.1854 - CER: 0.8957 - WER: 1.0000 - val_loss: 13.2539 - val_CER: 0.8538 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 45/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 14.1223 - CER: 0.8909 - WER: 1.0000\n",
            "Epoch 45: val_CER did not improve from 0.85385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 44; loss: 14.122315406799316; CER: 0.8970085382461548; WER: 1.0; val_loss: 12.862768173217773; val_CER: 0.857692301273346; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 14.1223 - CER: 0.8912 - WER: 1.0000 - val_loss: 12.8628 - val_CER: 0.8577 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 46/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 13.8749 - CER: 0.8732 - WER: 1.0000\n",
            "Epoch 46: val_CER did not improve from 0.85385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 45; loss: 13.874855041503906; CER: 0.8705129623413086; WER: 1.0; val_loss: 16.028852462768555; val_CER: 0.9346153736114502; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 182ms/step - loss: 13.8749 - CER: 0.8730 - WER: 1.0000 - val_loss: 16.0289 - val_CER: 0.9346 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 47/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 13.6660 - CER: 0.8644 - WER: 1.0000\n",
            "Epoch 47: val_CER did not improve from 0.85385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 46; loss: 13.66601276397705; CER: 0.8574786186218262; WER: 1.0; val_loss: 16.77901840209961; val_CER: 0.9230769276618958; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 244ms/step - loss: 13.6660 - CER: 0.8640 - WER: 1.0000 - val_loss: 16.7790 - val_CER: 0.9231 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 48/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 13.4805 - CER: 0.8371 - WER: 1.0000\n",
            "Epoch 48: val_CER did not improve from 0.85385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 47; loss: 13.480504035949707; CER: 0.8391025066375732; WER: 1.0; val_loss: 14.822422981262207; val_CER: 0.9115384817123413; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 184ms/step - loss: 13.4805 - CER: 0.8372 - WER: 1.0000 - val_loss: 14.8224 - val_CER: 0.9115 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 49/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 13.1530 - CER: 0.8325 - WER: 1.0000\n",
            "Epoch 49: val_CER improved from 0.85385 to 0.79808, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 48; loss: 13.15298843383789; CER: 0.8228632211685181; WER: 1.0; val_loss: 12.806976318359375; val_CER: 0.7980769276618958; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 553ms/step - loss: 13.1530 - CER: 0.8319 - WER: 1.0000 - val_loss: 12.8070 - val_CER: 0.7981 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 50/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.8689 - CER: 0.7969 - WER: 1.0000\n",
            "Epoch 50: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 49; loss: 12.868911743164062; CER: 0.7952991127967834; WER: 1.0; val_loss: 14.462520599365234; val_CER: 0.8807691931724548; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 205ms/step - loss: 12.8689 - CER: 0.7968 - WER: 1.0000 - val_loss: 14.4625 - val_CER: 0.8808 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 51/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.6427 - CER: 0.7793 - WER: 0.9997\n",
            "Epoch 51: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 50; loss: 12.642660140991211; CER: 0.7779915928840637; WER: 0.9989316463470459; val_loss: 14.475131034851074; val_CER: 0.875; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 207ms/step - loss: 12.6427 - CER: 0.7792 - WER: 0.9996 - val_loss: 14.4751 - val_CER: 0.8750 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 52/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.5034 - CER: 0.7838 - WER: 1.0000\n",
            "Epoch 52: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 51; loss: 12.503368377685547; CER: 0.7792734503746033; WER: 1.0; val_loss: 13.16695785522461; val_CER: 0.8480768799781799; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 248ms/step - loss: 12.5034 - CER: 0.7835 - WER: 1.0000 - val_loss: 13.1670 - val_CER: 0.8481 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 53/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.3423 - CER: 0.7759 - WER: 1.0000\n",
            "Epoch 53: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 52; loss: 12.342291831970215; CER: 0.7698718309402466; WER: 1.0; val_loss: 15.699265480041504; val_CER: 0.9096154570579529; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 12.3423 - CER: 0.7755 - WER: 1.0000 - val_loss: 15.6993 - val_CER: 0.9096 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 54/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 12.0324 - CER: 0.7332 - WER: 0.9984\n",
            "Epoch 54: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 53; loss: 12.03243350982666; CER: 0.7397435307502747; WER: 0.9989316463470459; val_loss: 15.792784690856934; val_CER: 0.8615384697914124; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 229ms/step - loss: 12.0324 - CER: 0.7336 - WER: 0.9984 - val_loss: 15.7928 - val_CER: 0.8615 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 55/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 11.6794 - CER: 0.7247 - WER: 1.0000\n",
            "Epoch 55: val_CER did not improve from 0.79808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 54; loss: 11.67944049835205; CER: 0.7254273295402527; WER: 1.0; val_loss: 14.99316120147705; val_CER: 0.8403846025466919; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 230ms/step - loss: 11.6794 - CER: 0.7248 - WER: 1.0000 - val_loss: 14.9932 - val_CER: 0.8404 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 56/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 11.4701 - CER: 0.6987 - WER: 0.9994\n",
            "Epoch 56: val_CER improved from 0.79808 to 0.72692, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 55; loss: 11.4700927734375; CER: 0.7055555582046509; WER: 0.9989316463470459; val_loss: 11.364073753356934; val_CER: 0.7269231081008911; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 205ms/step - loss: 11.4701 - CER: 0.6991 - WER: 0.9993 - val_loss: 11.3641 - val_CER: 0.7269 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 57/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 11.1297 - CER: 0.6946 - WER: 0.9978\n",
            "Epoch 57: val_CER did not improve from 0.72692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 56; loss: 11.12968921661377; CER: 0.6844017505645752; WER: 0.9967948794364929; val_loss: 15.148978233337402; val_CER: 0.8384615182876587; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 182ms/step - loss: 11.1297 - CER: 0.6940 - WER: 0.9978 - val_loss: 15.1490 - val_CER: 0.8385 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 58/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.8574 - CER: 0.6780 - WER: 0.9937\n",
            "Epoch 58: val_CER improved from 0.72692 to 0.65000, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 57; loss: 10.857392311096191; CER: 0.672863245010376; WER: 0.9903846383094788; val_loss: 10.431063652038574; val_CER: 0.6500000357627869; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 283ms/step - loss: 10.8574 - CER: 0.6777 - WER: 0.9935 - val_loss: 10.4311 - val_CER: 0.6500 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 59/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.7152 - CER: 0.6629 - WER: 0.9940\n",
            "Epoch 59: val_CER improved from 0.65000 to 0.62500, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 58; loss: 10.715190887451172; CER: 0.6600427031517029; WER: 0.992521345615387; val_loss: 9.583844184875488; val_CER: 0.625; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 206ms/step - loss: 10.7152 - CER: 0.6627 - WER: 0.9939 - val_loss: 9.5838 - val_CER: 0.6250 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 60/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.2550 - CER: 0.6289 - WER: 0.9915\n",
            "Epoch 60: val_CER did not improve from 0.62500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 59; loss: 10.255037307739258; CER: 0.6264957785606384; WER: 0.9903846383094788; val_loss: 11.777741432189941; val_CER: 0.7326923608779907; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 202ms/step - loss: 10.2550 - CER: 0.6287 - WER: 0.9914 - val_loss: 11.7777 - val_CER: 0.7327 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 61/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 10.2399 - CER: 0.6261 - WER: 0.9804\n",
            "Epoch 61: val_CER did not improve from 0.62500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 60; loss: 10.239944458007812; CER: 0.6297008991241455; WER: 0.9871794581413269; val_loss: 10.718011856079102; val_CER: 0.6423076391220093; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 251ms/step - loss: 10.2399 - CER: 0.6263 - WER: 0.9809 - val_loss: 10.7180 - val_CER: 0.6423 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 62/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 9.9960 - CER: 0.6320 - WER: 0.9879\n",
            "Epoch 62: val_CER did not improve from 0.62500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 61; loss: 9.995962142944336; CER: 0.6205127835273743; WER: 0.9818376302719116; val_loss: 11.734405517578125; val_CER: 0.7057692408561707; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 179ms/step - loss: 9.9960 - CER: 0.6312 - WER: 0.9875 - val_loss: 11.7344 - val_CER: 0.7058 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 63/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 9.9054 - CER: 0.6008 - WER: 0.9830\n",
            "Epoch 63: val_CER did not improve from 0.62500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 62; loss: 9.90539836883545; CER: 0.6038462519645691; WER: 0.9797008633613586; val_loss: 11.018627166748047; val_CER: 0.6846153736114502; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 9.9054 - CER: 0.6010 - WER: 0.9828 - val_loss: 11.0186 - val_CER: 0.6846 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 64/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 9.1573 - CER: 0.5647 - WER: 0.9636\n",
            "Epoch 64: val_CER improved from 0.62500 to 0.57308, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 63; loss: 9.157286643981934; CER: 0.5735042691230774; WER: 0.9700854420661926; val_loss: 9.529356956481934; val_CER: 0.5730769634246826; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 259ms/step - loss: 9.1573 - CER: 0.5652 - WER: 0.9640 - val_loss: 9.5294 - val_CER: 0.5731 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 65/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 9.2884 - CER: 0.5822 - WER: 0.9841\n",
            "Epoch 65: val_CER did not improve from 0.57308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 64; loss: 9.288366317749023; CER: 0.5833333134651184; WER: 0.9797008633613586; val_loss: 10.98973560333252; val_CER: 0.6942307949066162; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 9.2884 - CER: 0.5823 - WER: 0.9838 - val_loss: 10.9897 - val_CER: 0.6942 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 66/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.8861 - CER: 0.5719 - WER: 0.9721\n",
            "Epoch 66: val_CER improved from 0.57308 to 0.56731, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 65; loss: 8.886113166809082; CER: 0.5688034296035767; WER: 0.9700854420661926; val_loss: 8.765950202941895; val_CER: 0.567307710647583; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 216ms/step - loss: 8.8861 - CER: 0.5717 - WER: 0.9720 - val_loss: 8.7660 - val_CER: 0.5673 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 67/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.4193 - CER: 0.5274 - WER: 0.9411\n",
            "Epoch 67: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 66; loss: 8.419266700744629; CER: 0.5341880321502686; WER: 0.9476495981216431; val_loss: 9.557940483093262; val_CER: 0.6173076629638672; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 221ms/step - loss: 8.4193 - CER: 0.5278 - WER: 0.9415 - val_loss: 9.5579 - val_CER: 0.6173 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 68/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.3327 - CER: 0.5133 - WER: 0.9693\n",
            "Epoch 68: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 67; loss: 8.332691192626953; CER: 0.5250000357627869; WER: 0.9604700803756714; val_loss: 11.190648078918457; val_CER: 0.7115384340286255; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 200ms/step - loss: 8.3327 - CER: 0.5140 - WER: 0.9688 - val_loss: 11.1906 - val_CER: 0.7115 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 69/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.3154 - CER: 0.5218 - WER: 0.9364\n",
            "Epoch 69: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 68; loss: 8.315374374389648; CER: 0.5181624293327332; WER: 0.942307710647583; val_loss: 9.574498176574707; val_CER: 0.6230769753456116; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 528ms/step - loss: 8.3154 - CER: 0.5215 - WER: 0.9368 - val_loss: 9.5745 - val_CER: 0.6231 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 70/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 8.1302 - CER: 0.5297 - WER: 0.9446\n",
            "Epoch 70: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 69; loss: 8.13022518157959; CER: 0.5153846740722656; WER: 0.9465811848640442; val_loss: 9.912080764770508; val_CER: 0.625; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 8.1302 - CER: 0.5288 - WER: 0.9447 - val_loss: 9.9121 - val_CER: 0.6250 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 71/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.8608 - CER: 0.5140 - WER: 0.9354\n",
            "Epoch 71: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 70; loss: 7.860783576965332; CER: 0.5076923370361328; WER: 0.9294871687889099; val_loss: 9.20846939086914; val_CER: 0.5692307353019714; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 7.8608 - CER: 0.5136 - WER: 0.9350 - val_loss: 9.2085 - val_CER: 0.5692 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 72/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.4970 - CER: 0.4937 - WER: 0.9377\n",
            "Epoch 72: val_CER did not improve from 0.56731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 71; loss: 7.497013092041016; CER: 0.47542741894721985; WER: 0.9220085740089417; val_loss: 9.59573745727539; val_CER: 0.5884615182876587; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 240ms/step - loss: 7.4970 - CER: 0.4926 - WER: 0.9368 - val_loss: 9.5957 - val_CER: 0.5885 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 73/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.2061 - CER: 0.4575 - WER: 0.9146\n",
            "Epoch 73: val_CER improved from 0.56731 to 0.49808, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 72; loss: 7.206112384796143; CER: 0.45876067876815796; WER: 0.9091880321502686; val_loss: 8.102535247802734; val_CER: 0.4980769157409668; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 552ms/step - loss: 7.2061 - CER: 0.4576 - WER: 0.9143 - val_loss: 8.1025 - val_CER: 0.4981 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 74/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 7.1809 - CER: 0.4617 - WER: 0.8885\n",
            "Epoch 74: val_CER improved from 0.49808 to 0.38462, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 73; loss: 7.180854320526123; CER: 0.45491451025009155; WER: 0.8846153616905212; val_loss: 6.176273822784424; val_CER: 0.38461539149284363; val_WER: 0.9038461446762085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 317ms/step - loss: 7.1809 - CER: 0.4613 - WER: 0.8883 - val_loss: 6.1763 - val_CER: 0.3846 - val_WER: 0.9038 - lr: 9.0000e-04\n",
            "Epoch 75/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.9873 - CER: 0.4470 - WER: 0.9048\n",
            "Epoch 75: val_CER improved from 0.38462 to 0.30000, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 74; loss: 6.987290382385254; CER: 0.44380345940589905; WER: 0.8963675498962402; val_loss: 4.888787269592285; val_CER: 0.29999998211860657; val_WER: 0.8269230723381042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 199ms/step - loss: 6.9873 - CER: 0.4468 - WER: 0.9043 - val_loss: 4.8888 - val_CER: 0.3000 - val_WER: 0.8269 - lr: 9.0000e-04\n",
            "Epoch 76/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.8834 - CER: 0.4345 - WER: 0.8696\n",
            "Epoch 76: val_CER did not improve from 0.30000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 75; loss: 6.883439064025879; CER: 0.4433760643005371; WER: 0.8867521286010742; val_loss: 6.41386079788208; val_CER: 0.4096153974533081; val_WER: 0.942307710647583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 6.8834 - CER: 0.4351 - WER: 0.8707 - val_loss: 6.4139 - val_CER: 0.4096 - val_WER: 0.9423 - lr: 9.0000e-04\n",
            "Epoch 77/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.6926 - CER: 0.4289 - WER: 0.8684\n",
            "Epoch 77: val_CER did not improve from 0.30000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 76; loss: 6.692618370056152; CER: 0.4309828579425812; WER: 0.882478654384613; val_loss: 9.15478801727295; val_CER: 0.517307698726654; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 236ms/step - loss: 6.6926 - CER: 0.4290 - WER: 0.8693 - val_loss: 9.1548 - val_CER: 0.5173 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 78/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.3237 - CER: 0.4022 - WER: 0.8633\n",
            "Epoch 78: val_CER did not improve from 0.30000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 77; loss: 6.323733806610107; CER: 0.40256407856941223; WER: 0.8611111044883728; val_loss: 10.362317085266113; val_CER: 0.5942307710647583; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 9s 558ms/step - loss: 6.3237 - CER: 0.4023 - WER: 0.8631 - val_loss: 10.3623 - val_CER: 0.5942 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 79/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.4756 - CER: 0.4166 - WER: 0.8621\n",
            "Epoch 79: val_CER improved from 0.30000 to 0.22885, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 78; loss: 6.475599765777588; CER: 0.4128205180168152; WER: 0.8557692170143127; val_loss: 3.7503459453582764; val_CER: 0.22884614765644073; val_WER: 0.7211538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 221ms/step - loss: 6.4756 - CER: 0.4163 - WER: 0.8617 - val_loss: 3.7503 - val_CER: 0.2288 - val_WER: 0.7212 - lr: 9.0000e-04\n",
            "Epoch 80/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.1359 - CER: 0.3929 - WER: 0.8382\n",
            "Epoch 80: val_CER improved from 0.22885 to 0.19615, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 79; loss: 6.135868549346924; CER: 0.3897435665130615; WER: 0.8311966061592102; val_loss: 3.4181692600250244; val_CER: 0.19615386426448822; val_WER: 0.6442307829856873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 207ms/step - loss: 6.1359 - CER: 0.3927 - WER: 0.8378 - val_loss: 3.4182 - val_CER: 0.1962 - val_WER: 0.6442 - lr: 9.0000e-04\n",
            "Epoch 81/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 6.1629 - CER: 0.3842 - WER: 0.8163\n",
            "Epoch 81: val_CER improved from 0.19615 to 0.16346, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 80; loss: 6.162866592407227; CER: 0.3861111104488373; WER: 0.8194444179534912; val_loss: 3.0780868530273438; val_CER: 0.16346153616905212; val_WER: 0.557692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 6.1629 - CER: 0.3843 - WER: 0.8165 - val_loss: 3.0781 - val_CER: 0.1635 - val_WER: 0.5577 - lr: 9.0000e-04\n",
            "Epoch 82/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.8818 - CER: 0.3965 - WER: 0.8166\n",
            "Epoch 82: val_CER did not improve from 0.16346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 81; loss: 5.881803512573242; CER: 0.38055554032325745; WER: 0.8108974099159241; val_loss: 7.740083694458008; val_CER: 0.4615384638309479; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 256ms/step - loss: 5.8818 - CER: 0.3955 - WER: 0.8162 - val_loss: 7.7401 - val_CER: 0.4615 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 83/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.9188 - CER: 0.3900 - WER: 0.8175\n",
            "Epoch 83: val_CER did not improve from 0.16346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 82; loss: 5.918787956237793; CER: 0.3790598511695862; WER: 0.8194444179534912; val_loss: 8.833988189697266; val_CER: 0.5615384578704834; val_WER: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 5.9188 - CER: 0.3893 - WER: 0.8176 - val_loss: 8.8340 - val_CER: 0.5615 - val_WER: 1.0000 - lr: 9.0000e-04\n",
            "Epoch 84/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.7355 - CER: 0.3694 - WER: 0.8289\n",
            "Epoch 84: val_CER did not improve from 0.16346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 83; loss: 5.735531806945801; CER: 0.36346155405044556; WER: 0.8258547186851501; val_loss: 9.717569351196289; val_CER: 0.5596153736114502; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 181ms/step - loss: 5.7355 - CER: 0.3690 - WER: 0.8287 - val_loss: 9.7176 - val_CER: 0.5596 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 85/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.8104 - CER: 0.3799 - WER: 0.8379\n",
            "Epoch 85: val_CER improved from 0.16346 to 0.15769, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 84; loss: 5.810434818267822; CER: 0.3767094314098358; WER: 0.8333333134651184; val_loss: 3.0894172191619873; val_CER: 0.1576923280954361; val_WER: 0.567307710647583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 275ms/step - loss: 5.8104 - CER: 0.3797 - WER: 0.8376 - val_loss: 3.0894 - val_CER: 0.1577 - val_WER: 0.5673 - lr: 9.0000e-04\n",
            "Epoch 86/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.4215 - CER: 0.3521 - WER: 0.8049\n",
            "Epoch 86: val_CER improved from 0.15769 to 0.15000, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 85; loss: 5.421489238739014; CER: 0.34978631138801575; WER: 0.8044871687889099; val_loss: 2.6916251182556152; val_CER: 0.15000000596046448; val_WER: 0.5480769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 202ms/step - loss: 5.4215 - CER: 0.3520 - WER: 0.8049 - val_loss: 2.6916 - val_CER: 0.1500 - val_WER: 0.5481 - lr: 9.0000e-04\n",
            "Epoch 87/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.4485 - CER: 0.3422 - WER: 0.7637\n",
            "Epoch 87: val_CER did not improve from 0.15000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 86; loss: 5.4485321044921875; CER: 0.34166663885116577; WER: 0.7767093777656555; val_loss: 4.908771514892578; val_CER: 0.2846153974533081; val_WER: 0.8461538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 200ms/step - loss: 5.4485 - CER: 0.3422 - WER: 0.7645 - val_loss: 4.9088 - val_CER: 0.2846 - val_WER: 0.8462 - lr: 9.0000e-04\n",
            "Epoch 88/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.0694 - CER: 0.3231 - WER: 0.7699\n",
            "Epoch 88: val_CER improved from 0.15000 to 0.14038, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 87; loss: 5.069377899169922; CER: 0.32692304253578186; WER: 0.7649572491645813; val_loss: 2.594167470932007; val_CER: 0.14038461446762085; val_WER: 0.5480769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 206ms/step - loss: 5.0694 - CER: 0.3234 - WER: 0.7696 - val_loss: 2.5942 - val_CER: 0.1404 - val_WER: 0.5481 - lr: 9.0000e-04\n",
            "Epoch 89/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 5.1798 - CER: 0.3386 - WER: 0.7565\n",
            "Epoch 89: val_CER improved from 0.14038 to 0.11731, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 88; loss: 5.179750919342041; CER: 0.33696579933166504; WER: 0.7638888955116272; val_loss: 2.232828378677368; val_CER: 0.11730770021677017; val_WER: 0.48076921701431274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 200ms/step - loss: 5.1798 - CER: 0.3385 - WER: 0.7570 - val_loss: 2.2328 - val_CER: 0.1173 - val_WER: 0.4808 - lr: 9.0000e-04\n",
            "Epoch 90/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.7029 - CER: 0.2934 - WER: 0.7225\n",
            "Epoch 90: val_CER improved from 0.11731 to 0.09808, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 89; loss: 4.702931880950928; CER: 0.30085474252700806; WER: 0.742521345615387; val_loss: 1.8942644596099854; val_CER: 0.09807693213224411; val_WER: 0.42307692766189575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 199ms/step - loss: 4.7029 - CER: 0.2939 - WER: 0.7238 - val_loss: 1.8943 - val_CER: 0.0981 - val_WER: 0.4231 - lr: 9.0000e-04\n",
            "Epoch 91/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.7154 - CER: 0.2984 - WER: 0.7235\n",
            "Epoch 91: val_CER did not improve from 0.09808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 90; loss: 4.715373516082764; CER: 0.2995726466178894; WER: 0.7307692170143127; val_loss: 1.9045859575271606; val_CER: 0.10000000894069672; val_WER: 0.4038461446762085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 255ms/step - loss: 4.7154 - CER: 0.2985 - WER: 0.7240 - val_loss: 1.9046 - val_CER: 0.1000 - val_WER: 0.4038 - lr: 9.0000e-04\n",
            "Epoch 92/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.6074 - CER: 0.2903 - WER: 0.6937\n",
            "Epoch 92: val_CER did not improve from 0.09808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 91; loss: 4.607435703277588; CER: 0.2946580946445465; WER: 0.7158119678497314; val_loss: 7.675897598266602; val_CER: 0.45384615659713745; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 181ms/step - loss: 4.6074 - CER: 0.2906 - WER: 0.6951 - val_loss: 7.6759 - val_CER: 0.4538 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 93/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.6674 - CER: 0.3038 - WER: 0.7162\n",
            "Epoch 93: val_CER did not improve from 0.09808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 92; loss: 4.667369365692139; CER: 0.297649621963501; WER: 0.7222222089767456; val_loss: 9.507323265075684; val_CER: 0.5115384459495544; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 182ms/step - loss: 4.6674 - CER: 0.3034 - WER: 0.7166 - val_loss: 9.5073 - val_CER: 0.5115 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 94/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.5129 - CER: 0.2977 - WER: 0.7354\n",
            "Epoch 94: val_CER did not improve from 0.09808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 93; loss: 4.5128679275512695; CER: 0.2927350699901581; WER: 0.7329059839248657; val_loss: 1.8902140855789185; val_CER: 0.10769231617450714; val_WER: 0.4615384638309479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 271ms/step - loss: 4.5129 - CER: 0.2974 - WER: 0.7352 - val_loss: 1.8902 - val_CER: 0.1077 - val_WER: 0.4615 - lr: 9.0000e-04\n",
            "Epoch 95/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.5146 - CER: 0.2924 - WER: 0.6894\n",
            "Epoch 95: val_CER improved from 0.09808 to 0.08846, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 94; loss: 4.5146484375; CER: 0.29294872283935547; WER: 0.7179487347602844; val_loss: 1.6894006729125977; val_CER: 0.08846153318881989; val_WER: 0.36538460850715637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 203ms/step - loss: 4.5146 - CER: 0.2924 - WER: 0.6912 - val_loss: 1.6894 - val_CER: 0.0885 - val_WER: 0.3654 - lr: 9.0000e-04\n",
            "Epoch 96/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.2437 - CER: 0.2795 - WER: 0.6944\n",
            "Epoch 96: val_CER did not improve from 0.08846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 95; loss: 4.24365234375; CER: 0.27542734146118164; WER: 0.688034176826477; val_loss: 9.881561279296875; val_CER: 0.5019230246543884; val_WER: 0.9711538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 187ms/step - loss: 4.2437 - CER: 0.2792 - WER: 0.6940 - val_loss: 9.8816 - val_CER: 0.5019 - val_WER: 0.9712 - lr: 9.0000e-04\n",
            "Epoch 97/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.0773 - CER: 0.2599 - WER: 0.6544\n",
            "Epoch 97: val_CER did not improve from 0.08846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 96; loss: 4.077271938323975; CER: 0.25128206610679626; WER: 0.6463675498962402; val_loss: 2.5671768188476562; val_CER: 0.1576922982931137; val_WER: 0.557692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 270ms/step - loss: 4.0773 - CER: 0.2594 - WER: 0.6539 - val_loss: 2.5672 - val_CER: 0.1577 - val_WER: 0.5577 - lr: 9.0000e-04\n",
            "Epoch 98/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.1608 - CER: 0.2827 - WER: 0.6982\n",
            "Epoch 98: val_CER did not improve from 0.08846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 97; loss: 4.16079044342041; CER: 0.2758547067642212; WER: 0.6805555820465088; val_loss: 1.603826642036438; val_CER: 0.08846154808998108; val_WER: 0.36538460850715637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 182ms/step - loss: 4.1608 - CER: 0.2823 - WER: 0.6971 - val_loss: 1.6038 - val_CER: 0.0885 - val_WER: 0.3654 - lr: 9.0000e-04\n",
            "Epoch 99/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.9810 - CER: 0.2730 - WER: 0.6735\n",
            "Epoch 99: val_CER did not improve from 0.08846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 98; loss: 3.9809999465942383; CER: 0.2557692527770996; WER: 0.6538461446762085; val_loss: 10.655267715454102; val_CER: 0.567307710647583; val_WER: 0.9903846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 189ms/step - loss: 3.9810 - CER: 0.2719 - WER: 0.6722 - val_loss: 10.6553 - val_CER: 0.5673 - val_WER: 0.9904 - lr: 9.0000e-04\n",
            "Epoch 100/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 4.0457 - CER: 0.2491 - WER: 0.6514\n",
            "Epoch 100: val_CER improved from 0.08846 to 0.06923, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 99; loss: 4.045662879943848; CER: 0.25641030073165894; WER: 0.6698718070983887; val_loss: 1.3874070644378662; val_CER: 0.06923076510429382; val_WER: 0.26923078298568726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 281ms/step - loss: 4.0457 - CER: 0.2495 - WER: 0.6526 - val_loss: 1.3874 - val_CER: 0.0692 - val_WER: 0.2692 - lr: 9.0000e-04\n",
            "Epoch 101/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.8981 - CER: 0.2435 - WER: 0.6476\n",
            "Epoch 101: val_CER did not improve from 0.06923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 100; loss: 3.8981378078460693; CER: 0.24935896694660187; WER: 0.6378205418586731; val_loss: 1.5874848365783691; val_CER: 0.09038460999727249; val_WER: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 3.8981 - CER: 0.2438 - WER: 0.6470 - val_loss: 1.5875 - val_CER: 0.0904 - val_WER: 0.3750 - lr: 9.0000e-04\n",
            "Epoch 102/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.8644 - CER: 0.2458 - WER: 0.6450\n",
            "Epoch 102: val_CER did not improve from 0.06923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 101; loss: 3.864400625228882; CER: 0.25149571895599365; WER: 0.6388888955116272; val_loss: 1.5310194492340088; val_CER: 0.0942307710647583; val_WER: 0.4326923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 201ms/step - loss: 3.8644 - CER: 0.2462 - WER: 0.6447 - val_loss: 1.5310 - val_CER: 0.0942 - val_WER: 0.4327 - lr: 9.0000e-04\n",
            "Epoch 103/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.7565 - CER: 0.2251 - WER: 0.5969\n",
            "Epoch 103: val_CER improved from 0.06923 to 0.05769, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 102; loss: 3.756532907485962; CER: 0.23974359035491943; WER: 0.6367521286010742; val_loss: 1.1431779861450195; val_CER: 0.057692307978868484; val_WER: 0.26923078298568726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 200ms/step - loss: 3.7565 - CER: 0.2260 - WER: 0.5994 - val_loss: 1.1432 - val_CER: 0.0577 - val_WER: 0.2692 - lr: 9.0000e-04\n",
            "Epoch 104/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.4191 - CER: 0.2112 - WER: 0.5884\n",
            "Epoch 104: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 103; loss: 3.41908597946167; CER: 0.21303421258926392; WER: 0.5950854420661926; val_loss: 1.1442570686340332; val_CER: 0.05769231170415878; val_WER: 0.26923078298568726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 260ms/step - loss: 3.4191 - CER: 0.2113 - WER: 0.5888 - val_loss: 1.1443 - val_CER: 0.0577 - val_WER: 0.2692 - lr: 9.0000e-04\n",
            "Epoch 105/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.4493 - CER: 0.2291 - WER: 0.6246\n",
            "Epoch 105: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 104; loss: 3.4492850303649902; CER: 0.21965812146663666; WER: 0.5972222089767456; val_loss: 1.2509386539459229; val_CER: 0.07500000298023224; val_WER: 0.32692307233810425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 228ms/step - loss: 3.4493 - CER: 0.2286 - WER: 0.6229 - val_loss: 1.2509 - val_CER: 0.0750 - val_WER: 0.3269 - lr: 9.0000e-04\n",
            "Epoch 106/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.4397 - CER: 0.2101 - WER: 0.5885\n",
            "Epoch 106: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 105; loss: 3.439682960510254; CER: 0.2222222238779068; WER: 0.6036324501037598; val_loss: 1.1666860580444336; val_CER: 0.08076923340559006; val_WER: 0.32692307233810425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 384ms/step - loss: 3.4397 - CER: 0.2109 - WER: 0.5895 - val_loss: 1.1667 - val_CER: 0.0808 - val_WER: 0.3269 - lr: 9.0000e-04\n",
            "Epoch 107/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.4120 - CER: 0.2070 - WER: 0.5685\n",
            "Epoch 107: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 106; loss: 3.4119691848754883; CER: 0.2143162488937378; WER: 0.5876068472862244; val_loss: 1.3631260395050049; val_CER: 0.09038460999727249; val_WER: 0.39423078298568726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 325ms/step - loss: 3.4120 - CER: 0.2075 - WER: 0.5697 - val_loss: 1.3631 - val_CER: 0.0904 - val_WER: 0.3942 - lr: 9.0000e-04\n",
            "Epoch 108/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.3859 - CER: 0.2150 - WER: 0.5868\n",
            "Epoch 108: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 107; loss: 3.3859145641326904; CER: 0.2132478654384613; WER: 0.5908119678497314; val_loss: 1.2596776485443115; val_CER: 0.08269231021404266; val_WER: 0.3365384638309479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 7s 393ms/step - loss: 3.3859 - CER: 0.2148 - WER: 0.5871 - val_loss: 1.2597 - val_CER: 0.0827 - val_WER: 0.3365 - lr: 9.0000e-04\n",
            "Epoch 109/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.0547 - CER: 0.1936 - WER: 0.5560\n",
            "Epoch 109: val_CER did not improve from 0.05769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 108; loss: 3.054673433303833; CER: 0.19658119976520538; WER: 0.5705128312110901; val_loss: 1.3133240938186646; val_CER: 0.07884616404771805; val_WER: 0.3461538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 532ms/step - loss: 3.0547 - CER: 0.1938 - WER: 0.5569 - val_loss: 1.3133 - val_CER: 0.0788 - val_WER: 0.3462 - lr: 9.0000e-04\n",
            "Epoch 110/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.0164 - CER: 0.1892 - WER: 0.5232\n",
            "Epoch 110: val_CER improved from 0.05769 to 0.05577, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 109; loss: 3.016387462615967; CER: 0.1942307949066162; WER: 0.5373931527137756; val_loss: 0.9752062559127808; val_CER: 0.05576923117041588; val_WER: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 327ms/step - loss: 3.0164 - CER: 0.1895 - WER: 0.5240 - val_loss: 0.9752 - val_CER: 0.0558 - val_WER: 0.2500 - lr: 9.0000e-04\n",
            "Epoch 111/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.1497 - CER: 0.2061 - WER: 0.5648\n",
            "Epoch 111: val_CER did not improve from 0.05577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 110; loss: 3.1497437953948975; CER: 0.19807691872119904; WER: 0.5502136945724487; val_loss: 1.1603418588638306; val_CER: 0.06923076510429382; val_WER: 0.3173076808452606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 3.1497 - CER: 0.2056 - WER: 0.5639 - val_loss: 1.1603 - val_CER: 0.0692 - val_WER: 0.3173 - lr: 9.0000e-04\n",
            "Epoch 112/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 3.0192 - CER: 0.1947 - WER: 0.5444\n",
            "Epoch 112: val_CER did not improve from 0.05577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 111; loss: 3.0191714763641357; CER: 0.18995726108551025; WER: 0.5331196784973145; val_loss: 0.9748367071151733; val_CER: 0.05769231170415878; val_WER: 0.25961539149284363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 210ms/step - loss: 3.0192 - CER: 0.1944 - WER: 0.5437 - val_loss: 0.9748 - val_CER: 0.0577 - val_WER: 0.2596 - lr: 9.0000e-04\n",
            "Epoch 113/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.9663 - CER: 0.1877 - WER: 0.5702\n",
            "Epoch 113: val_CER did not improve from 0.05577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 112; loss: 2.966273546218872; CER: 0.19358976185321808; WER: 0.5747863054275513; val_loss: 9.988741874694824; val_CER: 0.48653843998908997; val_WER: 0.9711538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 2.9663 - CER: 0.1880 - WER: 0.5705 - val_loss: 9.9887 - val_CER: 0.4865 - val_WER: 0.9712 - lr: 9.0000e-04\n",
            "Epoch 114/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.7798 - CER: 0.1812 - WER: 0.5391\n",
            "Epoch 114: val_CER did not improve from 0.05577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 113; loss: 2.779845952987671; CER: 0.1844017207622528; WER: 0.5438033938407898; val_loss: 7.568000793457031; val_CER: 0.41730770468711853; val_WER: 0.942307710647583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 181ms/step - loss: 2.7798 - CER: 0.1814 - WER: 0.5394 - val_loss: 7.5680 - val_CER: 0.4173 - val_WER: 0.9423 - lr: 9.0000e-04\n",
            "Epoch 115/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.8234 - CER: 0.1824 - WER: 0.5381\n",
            "Epoch 115: val_CER did not improve from 0.05577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 114; loss: 2.823434591293335; CER: 0.18076924979686737; WER: 0.5299145579338074; val_loss: 0.9926686882972717; val_CER: 0.06730769574642181; val_WER: 0.29807692766189575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 198ms/step - loss: 2.8234 - CER: 0.1823 - WER: 0.5376 - val_loss: 0.9927 - val_CER: 0.0673 - val_WER: 0.2981 - lr: 9.0000e-04\n",
            "Epoch 116/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.8419 - CER: 0.1847 - WER: 0.5609\n",
            "Epoch 116: val_CER improved from 0.05577 to 0.05000, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 115; loss: 2.8418755531311035; CER: 0.1794871985912323; WER: 0.5288461446762085; val_loss: 0.9534284472465515; val_CER: 0.04999999701976776; val_WER: 0.23076923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 269ms/step - loss: 2.8419 - CER: 0.1844 - WER: 0.5589 - val_loss: 0.9534 - val_CER: 0.0500 - val_WER: 0.2308 - lr: 9.0000e-04\n",
            "Epoch 117/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.6729 - CER: 0.1649 - WER: 0.4909\n",
            "Epoch 117: val_CER improved from 0.05000 to 0.04808, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 116; loss: 2.6728804111480713; CER: 0.1696581244468689; WER: 0.504273533821106; val_loss: 0.7983713746070862; val_CER: 0.048076923936605453; val_WER: 0.23076923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 218ms/step - loss: 2.6729 - CER: 0.1652 - WER: 0.4917 - val_loss: 0.7984 - val_CER: 0.0481 - val_WER: 0.2308 - lr: 9.0000e-04\n",
            "Epoch 118/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.6289 - CER: 0.1722 - WER: 0.5015\n",
            "Epoch 118: val_CER did not improve from 0.04808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 117; loss: 2.6288952827453613; CER: 0.16880342364311218; WER: 0.49145299196243286; val_loss: 10.392298698425293; val_CER: 0.49038460850715637; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 206ms/step - loss: 2.6289 - CER: 0.1720 - WER: 0.5009 - val_loss: 10.3923 - val_CER: 0.4904 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 119/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.5939 - CER: 0.1797 - WER: 0.5269\n",
            "Epoch 119: val_CER did not improve from 0.04808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 118; loss: 2.5939300060272217; CER: 0.16688033938407898; WER: 0.5085470080375671; val_loss: 5.9412431716918945; val_CER: 0.3480769395828247; val_WER: 0.8653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 2.5939 - CER: 0.1789 - WER: 0.5258 - val_loss: 5.9412 - val_CER: 0.3481 - val_WER: 0.8654 - lr: 9.0000e-04\n",
            "Epoch 120/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.6977 - CER: 0.1801 - WER: 0.5235\n",
            "Epoch 120: val_CER did not improve from 0.04808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 119; loss: 2.697740316390991; CER: 0.17414529621601105; WER: 0.5128205418586731; val_loss: 0.926674485206604; val_CER: 0.05576923117041588; val_WER: 0.23076923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 184ms/step - loss: 2.6977 - CER: 0.1797 - WER: 0.5228 - val_loss: 0.9267 - val_CER: 0.0558 - val_WER: 0.2308 - lr: 9.0000e-04\n",
            "Epoch 121/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.4764 - CER: 0.1496 - WER: 0.4987\n",
            "Epoch 121: val_CER improved from 0.04808 to 0.04615, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 120; loss: 2.476372480392456; CER: 0.15833333134651184; WER: 0.5117521286010742; val_loss: 0.7636249661445618; val_CER: 0.04615384712815285; val_WER: 0.23076923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 215ms/step - loss: 2.4764 - CER: 0.1501 - WER: 0.4995 - val_loss: 0.7636 - val_CER: 0.0462 - val_WER: 0.2308 - lr: 9.0000e-04\n",
            "Epoch 122/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.3955 - CER: 0.1483 - WER: 0.4795\n",
            "Epoch 122: val_CER improved from 0.04615 to 0.04423, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 121; loss: 2.395522356033325; CER: 0.14957265555858612; WER: 0.4754273593425751; val_loss: 0.710375189781189; val_CER: 0.04423077404499054; val_WER: 0.2211538404226303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 256ms/step - loss: 2.3955 - CER: 0.1484 - WER: 0.4792 - val_loss: 0.7104 - val_CER: 0.0442 - val_WER: 0.2212 - lr: 9.0000e-04\n",
            "Epoch 123/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.4411 - CER: 0.1521 - WER: 0.4581\n",
            "Epoch 123: val_CER did not improve from 0.04423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 122; loss: 2.441098213195801; CER: 0.15833334624767303; WER: 0.4850427210330963; val_loss: 5.2923173904418945; val_CER: 0.3096154034137726; val_WER: 0.8365384340286255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 199ms/step - loss: 2.4411 - CER: 0.1525 - WER: 0.4598 - val_loss: 5.2923 - val_CER: 0.3096 - val_WER: 0.8365 - lr: 9.0000e-04\n",
            "Epoch 124/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.3846 - CER: 0.1435 - WER: 0.4382\n",
            "Epoch 124: val_CER improved from 0.04423 to 0.03269, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 123; loss: 2.3846449851989746; CER: 0.1438034325838089; WER: 0.4412393271923065; val_loss: 0.785224974155426; val_CER: 0.032692305743694305; val_WER: 0.16346153616905212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 203ms/step - loss: 2.3846 - CER: 0.1435 - WER: 0.4384 - val_loss: 0.7852 - val_CER: 0.0327 - val_WER: 0.1635 - lr: 9.0000e-04\n",
            "Epoch 125/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.2224 - CER: 0.1446 - WER: 0.4537\n",
            "Epoch 125: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 124; loss: 2.22240948677063; CER: 0.14123931527137756; WER: 0.43910256028175354; val_loss: 0.6533046364784241; val_CER: 0.032692305743694305; val_WER: 0.14423076808452606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 295ms/step - loss: 2.2224 - CER: 0.1444 - WER: 0.4528 - val_loss: 0.6533 - val_CER: 0.0327 - val_WER: 0.1442 - lr: 9.0000e-04\n",
            "Epoch 126/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1612 - CER: 0.1481 - WER: 0.4697\n",
            "Epoch 126: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 125; loss: 2.161184072494507; CER: 0.13910257816314697; WER: 0.43803417682647705; val_loss: 6.0897698402404785; val_CER: 0.33846157789230347; val_WER: 0.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 537ms/step - loss: 2.1612 - CER: 0.1475 - WER: 0.4677 - val_loss: 6.0898 - val_CER: 0.3385 - val_WER: 0.8750 - lr: 9.0000e-04\n",
            "Epoch 127/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1911 - CER: 0.1350 - WER: 0.4326\n",
            "Epoch 127: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 126; loss: 2.191147565841675; CER: 0.13653846085071564; WER: 0.4433760643005371; val_loss: 5.753966808319092; val_CER: 0.32307693362236023; val_WER: 0.8557692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 234ms/step - loss: 2.1911 - CER: 0.1351 - WER: 0.4333 - val_loss: 5.7540 - val_CER: 0.3231 - val_WER: 0.8558 - lr: 9.0000e-04\n",
            "Epoch 128/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1447 - CER: 0.1448 - WER: 0.4440\n",
            "Epoch 128: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 127; loss: 2.1446516513824463; CER: 0.13739316165447235; WER: 0.4326923191547394; val_loss: 0.5695459842681885; val_CER: 0.03461538627743721; val_WER: 0.17307692766189575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 188ms/step - loss: 2.1447 - CER: 0.1443 - WER: 0.4433 - val_loss: 0.5695 - val_CER: 0.0346 - val_WER: 0.1731 - lr: 9.0000e-04\n",
            "Epoch 129/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.2928 - CER: 0.1475 - WER: 0.4516\n",
            "Epoch 129: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 128; loss: 2.292832612991333; CER: 0.14529915153980255; WER: 0.45085468888282776; val_loss: 4.472442626953125; val_CER: 0.24230769276618958; val_WER: 0.7692307829856873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 191ms/step - loss: 2.2928 - CER: 0.1473 - WER: 0.4516 - val_loss: 4.4724 - val_CER: 0.2423 - val_WER: 0.7692 - lr: 9.0000e-04\n",
            "Epoch 130/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.0447 - CER: 0.1263 - WER: 0.4194\n",
            "Epoch 130: val_CER did not improve from 0.03269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 129; loss: 2.0446836948394775; CER: 0.12670940160751343; WER: 0.4188034236431122; val_loss: 0.7078041434288025; val_CER: 0.03653845936059952; val_WER: 0.16346153616905212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 242ms/step - loss: 2.0447 - CER: 0.1263 - WER: 0.4194 - val_loss: 0.7078 - val_CER: 0.0365 - val_WER: 0.1635 - lr: 9.0000e-04\n",
            "Epoch 131/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 2.1064 - CER: 0.1221 - WER: 0.4167\n",
            "Epoch 131: val_CER improved from 0.03269 to 0.02500, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 130; loss: 2.1064205169677734; CER: 0.1320512741804123; WER: 0.43482905626296997; val_loss: 0.6225345134735107; val_CER: 0.02499999850988388; val_WER: 0.10576923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 202ms/step - loss: 2.1064 - CER: 0.1227 - WER: 0.4178 - val_loss: 0.6225 - val_CER: 0.0250 - val_WER: 0.1058 - lr: 9.0000e-04\n",
            "Epoch 132/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.9478 - CER: 0.1269 - WER: 0.4146\n",
            "Epoch 132: val_CER did not improve from 0.02500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 131; loss: 1.9478132724761963; CER: 0.12948717176914215; WER: 0.4284188151359558; val_loss: 0.6731427311897278; val_CER: 0.032692309468984604; val_WER: 0.14423076808452606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 180ms/step - loss: 1.9478 - CER: 0.1270 - WER: 0.4154 - val_loss: 0.6731 - val_CER: 0.0327 - val_WER: 0.1442 - lr: 9.0000e-04\n",
            "Epoch 133/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.8873 - CER: 0.1247 - WER: 0.3974\n",
            "Epoch 133: val_CER improved from 0.02500 to 0.02308, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 132; loss: 1.8872852325439453; CER: 0.11987180262804031; WER: 0.39423078298568726; val_loss: 0.5238166451454163; val_CER: 0.023076923564076424; val_WER: 0.10576923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 387ms/step - loss: 1.8873 - CER: 0.1244 - WER: 0.3972 - val_loss: 0.5238 - val_CER: 0.0231 - val_WER: 0.1058 - lr: 9.0000e-04\n",
            "Epoch 134/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.9311 - CER: 0.1238 - WER: 0.4064\n",
            "Epoch 134: val_CER improved from 0.02308 to 0.01923, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 133; loss: 1.931061863899231; CER: 0.12350426614284515; WER: 0.41132479906082153; val_loss: 0.4233280122280121; val_CER: 0.01923076994717121; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 201ms/step - loss: 1.9311 - CER: 0.1237 - WER: 0.4067 - val_loss: 0.4233 - val_CER: 0.0192 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 135/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.7058 - CER: 0.1049 - WER: 0.3573\n",
            "Epoch 135: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 134; loss: 1.7058351039886475; CER: 0.10405983030796051; WER: 0.35363247990608215; val_loss: 0.5462999939918518; val_CER: 0.02500000223517418; val_WER: 0.11538461595773697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 6s 380ms/step - loss: 1.7058 - CER: 0.1048 - WER: 0.3571 - val_loss: 0.5463 - val_CER: 0.0250 - val_WER: 0.1154 - lr: 9.0000e-04\n",
            "Epoch 136/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.8636 - CER: 0.1169 - WER: 0.3816\n",
            "Epoch 136: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 135; loss: 1.8636153936386108; CER: 0.11645299941301346; WER: 0.38354700803756714; val_loss: 0.4230026602745056; val_CER: 0.021153846755623817; val_WER: 0.10576923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 1.8636 - CER: 0.1168 - WER: 0.3817 - val_loss: 0.4230 - val_CER: 0.0212 - val_WER: 0.1058 - lr: 9.0000e-04\n",
            "Epoch 137/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.7763 - CER: 0.1146 - WER: 0.3944\n",
            "Epoch 137: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 136; loss: 1.7762746810913086; CER: 0.11688034236431122; WER: 0.3985042870044708; val_loss: 0.4388429522514343; val_CER: 0.021153846755623817; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 247ms/step - loss: 1.7763 - CER: 0.1148 - WER: 0.3947 - val_loss: 0.4388 - val_CER: 0.0212 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 138/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.6715 - CER: 0.0973 - WER: 0.3229\n",
            "Epoch 138: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 137; loss: 1.6714599132537842; CER: 0.10192308574914932; WER: 0.345085471868515; val_loss: 0.5370936989784241; val_CER: 0.03076923079788685; val_WER: 0.1538461595773697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 180ms/step - loss: 1.6715 - CER: 0.0976 - WER: 0.3243 - val_loss: 0.5371 - val_CER: 0.0308 - val_WER: 0.1538 - lr: 9.0000e-04\n",
            "Epoch 139/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.7150 - CER: 0.1169 - WER: 0.3868\n",
            "Epoch 139: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 138; loss: 1.7150425910949707; CER: 0.11089743673801422; WER: 0.36645299196243286; val_loss: 0.6020492315292358; val_CER: 0.032692309468984604; val_WER: 0.14423076808452606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 180ms/step - loss: 1.7150 - CER: 0.1166 - WER: 0.3855 - val_loss: 0.6020 - val_CER: 0.0327 - val_WER: 0.1442 - lr: 9.0000e-04\n",
            "Epoch 140/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.6905 - CER: 0.1027 - WER: 0.3272\n",
            "Epoch 140: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 139; loss: 1.6905407905578613; CER: 0.10534188896417618; WER: 0.33867520093917847; val_loss: 12.182188987731934; val_CER: 0.5250000357627869; val_WER: 0.9807692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 262ms/step - loss: 1.6905 - CER: 0.1028 - WER: 0.3280 - val_loss: 12.1822 - val_CER: 0.5250 - val_WER: 0.9808 - lr: 9.0000e-04\n",
            "Epoch 141/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.7136 - CER: 0.1098 - WER: 0.3665\n",
            "Epoch 141: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 140; loss: 1.7135590314865112; CER: 0.1091880276799202; WER: 0.36858972907066345; val_loss: 0.4834236800670624; val_CER: 0.026923079043626785; val_WER: 0.13461539149284363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 199ms/step - loss: 1.7136 - CER: 0.1097 - WER: 0.3666 - val_loss: 0.4834 - val_CER: 0.0269 - val_WER: 0.1346 - lr: 9.0000e-04\n",
            "Epoch 142/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5636 - CER: 0.0948 - WER: 0.3342\n",
            "Epoch 142: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 141; loss: 1.5636155605316162; CER: 0.09273505210876465; WER: 0.33012819290161133; val_loss: 8.581442832946777; val_CER: 0.42307692766189575; val_WER: 0.9230769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 208ms/step - loss: 1.5636 - CER: 0.0946 - WER: 0.3339 - val_loss: 8.5814 - val_CER: 0.4231 - val_WER: 0.9231 - lr: 9.0000e-04\n",
            "Epoch 143/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.6425 - CER: 0.1055 - WER: 0.3409\n",
            "Epoch 143: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 142; loss: 1.6425353288650513; CER: 0.10363248735666275; WER: 0.33974358439445496; val_loss: 0.4703094959259033; val_CER: 0.01923076994717121; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 228ms/step - loss: 1.6425 - CER: 0.1054 - WER: 0.3408 - val_loss: 0.4703 - val_CER: 0.0192 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 144/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5624 - CER: 0.1029 - WER: 0.3542\n",
            "Epoch 144: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 143; loss: 1.5624421834945679; CER: 0.10064101964235306; WER: 0.35256409645080566; val_loss: 13.007332801818848; val_CER: 0.5403846502304077; val_WER: 0.9615384340286255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 1.5624 - CER: 0.1027 - WER: 0.3541 - val_loss: 13.0073 - val_CER: 0.5404 - val_WER: 0.9615 - lr: 9.0000e-04\n",
            "Epoch 145/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5979 - CER: 0.0966 - WER: 0.3476\n",
            "Epoch 145: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 144; loss: 1.597944974899292; CER: 0.09978631883859634; WER: 0.3461538553237915; val_loss: 0.3995243012905121; val_CER: 0.01923076994717121; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 196ms/step - loss: 1.5979 - CER: 0.0968 - WER: 0.3475 - val_loss: 0.3995 - val_CER: 0.0192 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 146/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.5081 - CER: 0.0958 - WER: 0.3355\n",
            "Epoch 146: val_CER did not improve from 0.01923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 145; loss: 1.5080991983413696; CER: 0.09743589162826538; WER: 0.33760684728622437; val_loss: 0.4617151916027069; val_CER: 0.01923076994717121; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 246ms/step - loss: 1.5081 - CER: 0.0959 - WER: 0.3356 - val_loss: 0.4617 - val_CER: 0.0192 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 147/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4791 - CER: 0.0942 - WER: 0.3393\n",
            "Epoch 147: val_CER improved from 0.01923 to 0.01538, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 146; loss: 1.4790518283843994; CER: 0.09444444626569748; WER: 0.33867520093917847; val_loss: 0.3963443338871002; val_CER: 0.015384615398943424; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 205ms/step - loss: 1.4791 - CER: 0.0942 - WER: 0.3392 - val_loss: 0.3963 - val_CER: 0.0154 - val_WER: 0.0673 - lr: 9.0000e-04\n",
            "Epoch 148/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4972 - CER: 0.0955 - WER: 0.3333\n",
            "Epoch 148: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 147; loss: 1.497159481048584; CER: 0.09636751562356949; WER: 0.33974358439445496; val_loss: 2.1363348960876465; val_CER: 0.13461539149284363; val_WER: 0.48076921701431274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 202ms/step - loss: 1.4972 - CER: 0.0956 - WER: 0.3337 - val_loss: 2.1363 - val_CER: 0.1346 - val_WER: 0.4808 - lr: 9.0000e-04\n",
            "Epoch 149/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.4391 - CER: 0.0871 - WER: 0.3084\n",
            "Epoch 149: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 148; loss: 1.439106822013855; CER: 0.08974359929561615; WER: 0.3173076808452606; val_loss: 0.45326077938079834; val_CER: 0.02500000223517418; val_WER: 0.11538461595773697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 241ms/step - loss: 1.4391 - CER: 0.0873 - WER: 0.3089 - val_loss: 0.4533 - val_CER: 0.0250 - val_WER: 0.1154 - lr: 9.0000e-04\n",
            "Epoch 150/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3356 - CER: 0.0808 - WER: 0.2872\n",
            "Epoch 150: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 149; loss: 1.3355627059936523; CER: 0.0833333358168602; WER: 0.29700854420661926; val_loss: 8.455548286437988; val_CER: 0.38846156001091003; val_WER: 0.9230769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 1.3356 - CER: 0.0810 - WER: 0.2878 - val_loss: 8.4555 - val_CER: 0.3885 - val_WER: 0.9231 - lr: 9.0000e-04\n",
            "Epoch 151/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3353 - CER: 0.0916 - WER: 0.3125\n",
            "Epoch 151: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 150; loss: 1.3352552652359009; CER: 0.08504272997379303; WER: 0.29914531111717224; val_loss: 0.3505338728427887; val_CER: 0.021153846755623817; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 216ms/step - loss: 1.3353 - CER: 0.0912 - WER: 0.3116 - val_loss: 0.3505 - val_CER: 0.0212 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 152/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3780 - CER: 0.0907 - WER: 0.3210\n",
            "Epoch 152: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 151; loss: 1.3780404329299927; CER: 0.08782051503658295; WER: 0.31410256028175354; val_loss: 0.4240235686302185; val_CER: 0.023076923564076424; val_WER: 0.10576923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 196ms/step - loss: 1.3780 - CER: 0.0905 - WER: 0.3206 - val_loss: 0.4240 - val_CER: 0.0231 - val_WER: 0.1058 - lr: 9.0000e-04\n",
            "Epoch 153/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3312 - CER: 0.0875 - WER: 0.3169\n",
            "Epoch 153: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 152; loss: 1.3312333822250366; CER: 0.08782050758600235; WER: 0.3194444477558136; val_loss: 8.833521842956543; val_CER: 0.39230772852897644; val_WER: 0.9038461446762085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 532ms/step - loss: 1.3312 - CER: 0.0876 - WER: 0.3170 - val_loss: 8.8335 - val_CER: 0.3923 - val_WER: 0.9038 - lr: 9.0000e-04\n",
            "Epoch 154/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.3950 - CER: 0.0890 - WER: 0.3212\n",
            "Epoch 154: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 153; loss: 1.3950446844100952; CER: 0.08888888359069824; WER: 0.31410256028175354; val_loss: 0.3376159369945526; val_CER: 0.01923076994717121; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 1.3950 - CER: 0.0890 - WER: 0.3208 - val_loss: 0.3376 - val_CER: 0.0192 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 155/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2785 - CER: 0.0770 - WER: 0.2712\n",
            "Epoch 155: val_CER did not improve from 0.01538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 154; loss: 1.2784957885742188; CER: 0.07799145579338074; WER: 0.2788461446762085; val_loss: 1.0688115358352661; val_CER: 0.07115384936332703; val_WER: 0.2788461446762085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 183ms/step - loss: 1.2785 - CER: 0.0770 - WER: 0.2716 - val_loss: 1.0688 - val_CER: 0.0712 - val_WER: 0.2788 - lr: 9.0000e-04\n",
            "Epoch 156/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2611 - CER: 0.0782 - WER: 0.2938\n",
            "Epoch 156: val_CER improved from 0.01538 to 0.00962, saving model to Models/02_captcha_to_text/202305021409/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 155; loss: 1.2611452341079712; CER: 0.07777777314186096; WER: 0.2895299196243286; val_loss: 0.41516491770744324; val_CER: 0.009615384973585606; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 218ms/step - loss: 1.2611 - CER: 0.0781 - WER: 0.2936 - val_loss: 0.4152 - val_CER: 0.0096 - val_WER: 0.0481 - lr: 9.0000e-04\n",
            "Epoch 157/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2148 - CER: 0.0772 - WER: 0.2829\n",
            "Epoch 157: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 156; loss: 1.214827537536621; CER: 0.0784188061952591; WER: 0.2905983030796051; val_loss: 0.3012535572052002; val_CER: 0.015384615398943424; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 281ms/step - loss: 1.2148 - CER: 0.0773 - WER: 0.2833 - val_loss: 0.3013 - val_CER: 0.0154 - val_WER: 0.0769 - lr: 9.0000e-04\n",
            "Epoch 158/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1691 - CER: 0.0785 - WER: 0.2795\n",
            "Epoch 158: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 157; loss: 1.1690597534179688; CER: 0.07414530217647552; WER: 0.27243590354919434; val_loss: 8.469529151916504; val_CER: 0.35769230127334595; val_WER: 0.8846153616905212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 212ms/step - loss: 1.1691 - CER: 0.0782 - WER: 0.2790 - val_loss: 8.4695 - val_CER: 0.3577 - val_WER: 0.8846 - lr: 9.0000e-04\n",
            "Epoch 159/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2730 - CER: 0.0723 - WER: 0.2645\n",
            "Epoch 159: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 158; loss: 1.2729874849319458; CER: 0.07927350699901581; WER: 0.2895299196243286; val_loss: 0.3426903188228607; val_CER: 0.01923076994717121; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 185ms/step - loss: 1.2730 - CER: 0.0728 - WER: 0.2661 - val_loss: 0.3427 - val_CER: 0.0192 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 160/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.2027 - CER: 0.0789 - WER: 0.2796\n",
            "Epoch 160: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 159; loss: 1.2027146816253662; CER: 0.07307692617177963; WER: 0.27136752009391785; val_loss: 0.3744810223579407; val_CER: 0.017307693138718605; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 258ms/step - loss: 1.2027 - CER: 0.0786 - WER: 0.2791 - val_loss: 0.3745 - val_CER: 0.0173 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 161/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0492 - CER: 0.0670 - WER: 0.2532\n",
            "Epoch 161: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 160; loss: 1.0492223501205444; CER: 0.06239316239953041; WER: 0.2361111044883728; val_loss: 0.40005192160606384; val_CER: 0.02500000223517418; val_WER: 0.11538461595773697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 1.0492 - CER: 0.0667 - WER: 0.2521 - val_loss: 0.4001 - val_CER: 0.0250 - val_WER: 0.1154 - lr: 9.0000e-04\n",
            "Epoch 162/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0397 - CER: 0.0681 - WER: 0.2479\n",
            "Epoch 162: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 161; loss: 1.039724349975586; CER: 0.06688034534454346; WER: 0.25534188747406006; val_loss: 0.3996748626232147; val_CER: 0.021153846755623817; val_WER: 0.10576923191547394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 187ms/step - loss: 1.0397 - CER: 0.0680 - WER: 0.2484 - val_loss: 0.3997 - val_CER: 0.0212 - val_WER: 0.1058 - lr: 9.0000e-04\n",
            "Epoch 163/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1485 - CER: 0.0641 - WER: 0.2399\n",
            "Epoch 163: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 162; loss: 1.148528814315796; CER: 0.0694444477558136; WER: 0.2532051205635071; val_loss: 11.802447319030762; val_CER: 0.5076923370361328; val_WER: 0.9711538553237915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 244ms/step - loss: 1.1485 - CER: 0.0645 - WER: 0.2407 - val_loss: 11.8024 - val_CER: 0.5077 - val_WER: 0.9712 - lr: 9.0000e-04\n",
            "Epoch 164/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.1500 - CER: 0.0620 - WER: 0.2389\n",
            "Epoch 164: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 163; loss: 1.150046467781067; CER: 0.0713675245642662; WER: 0.2617521286010742; val_loss: 5.0906219482421875; val_CER: 0.2480769157409668; val_WER: 0.7692307829856873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 214ms/step - loss: 1.1500 - CER: 0.0626 - WER: 0.2403 - val_loss: 5.0906 - val_CER: 0.2481 - val_WER: 0.7692 - lr: 9.0000e-04\n",
            "Epoch 165/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0747 - CER: 0.0633 - WER: 0.2357\n",
            "Epoch 165: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 164; loss: 1.0746595859527588; CER: 0.06602563709020615; WER: 0.24145299196243286; val_loss: 0.3250522017478943; val_CER: 0.017307691276073456; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 200ms/step - loss: 1.0747 - CER: 0.0635 - WER: 0.2360 - val_loss: 0.3251 - val_CER: 0.0173 - val_WER: 0.0769 - lr: 9.0000e-04\n",
            "Epoch 166/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0576 - CER: 0.0667 - WER: 0.2587\n",
            "Epoch 166: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 165; loss: 1.0575518608093262; CER: 0.06623931974172592; WER: 0.25427350401878357; val_loss: 0.36076971888542175; val_CER: 0.013461539521813393; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 235ms/step - loss: 1.0576 - CER: 0.0666 - WER: 0.2584 - val_loss: 0.3608 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 9.0000e-04\n",
            "Epoch 167/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0559 - CER: 0.0680 - WER: 0.2474\n",
            "Epoch 167: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 166; loss: 1.0558984279632568; CER: 0.06730768084526062; WER: 0.24786324799060822; val_loss: 0.324303537607193; val_CER: 0.013461539521813393; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 229ms/step - loss: 1.0559 - CER: 0.0680 - WER: 0.2475 - val_loss: 0.3243 - val_CER: 0.0135 - val_WER: 0.0673 - lr: 9.0000e-04\n",
            "Epoch 168/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0610 - CER: 0.0649 - WER: 0.2546\n",
            "Epoch 168: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 167; loss: 1.0610188245773315; CER: 0.06495726853609085; WER: 0.25; val_loss: 0.32865700125694275; val_CER: 0.013461539521813393; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 197ms/step - loss: 1.0610 - CER: 0.0649 - WER: 0.2543 - val_loss: 0.3287 - val_CER: 0.0135 - val_WER: 0.0673 - lr: 9.0000e-04\n",
            "Epoch 169/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9448 - CER: 0.0526 - WER: 0.1993\n",
            "Epoch 169: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 168; loss: 0.9447879791259766; CER: 0.05833333730697632; WER: 0.21474358439445496; val_loss: 0.3972913324832916; val_CER: 0.01923076994717121; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 192ms/step - loss: 0.9448 - CER: 0.0530 - WER: 0.2003 - val_loss: 0.3973 - val_CER: 0.0192 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 170/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9737 - CER: 0.0629 - WER: 0.2330\n",
            "Epoch 170: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 169; loss: 0.9737348556518555; CER: 0.061538469046354294; WER: 0.22649572789669037; val_loss: 0.37786582112312317; val_CER: 0.01923076994717121; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 253ms/step - loss: 0.9737 - CER: 0.0628 - WER: 0.2326 - val_loss: 0.3779 - val_CER: 0.0192 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 171/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9205 - CER: 0.0595 - WER: 0.2278\n",
            "Epoch 171: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 170; loss: 0.9204755425453186; CER: 0.058974359184503555; WER: 0.22756409645080566; val_loss: 0.3776696026325226; val_CER: 0.017307693138718605; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 201ms/step - loss: 0.9205 - CER: 0.0595 - WER: 0.2278 - val_loss: 0.3777 - val_CER: 0.0173 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 172/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9525 - CER: 0.0603 - WER: 0.2525\n",
            "Epoch 172: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 171; loss: 0.9524950981140137; CER: 0.062179483473300934; WER: 0.25641027092933655; val_loss: 0.40905582904815674; val_CER: 0.017307693138718605; val_WER: 0.08653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 195ms/step - loss: 0.9525 - CER: 0.0604 - WER: 0.2528 - val_loss: 0.4091 - val_CER: 0.0173 - val_WER: 0.0865 - lr: 9.0000e-04\n",
            "Epoch 173/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 1.0074 - CER: 0.0628 - WER: 0.2344\n",
            "Epoch 173: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 172; loss: 1.0073692798614502; CER: 0.06410256028175354; WER: 0.24358974397182465; val_loss: 10.528350830078125; val_CER: 0.45192310214042664; val_WER: 0.9615384340286255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 299ms/step - loss: 1.0074 - CER: 0.0629 - WER: 0.2349 - val_loss: 10.5284 - val_CER: 0.4519 - val_WER: 0.9615 - lr: 9.0000e-04\n",
            "Epoch 174/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9460 - CER: 0.0582 - WER: 0.2154\n",
            "Epoch 174: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 173; loss: 0.9459793567657471; CER: 0.05982905998826027; WER: 0.21688033640384674; val_loss: 0.3207126557826996; val_CER: 0.015384615398943424; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 237ms/step - loss: 0.9460 - CER: 0.0583 - WER: 0.2155 - val_loss: 0.3207 - val_CER: 0.0154 - val_WER: 0.0673 - lr: 9.0000e-04\n",
            "Epoch 175/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9008 - CER: 0.0578 - WER: 0.2341\n",
            "Epoch 175: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 174; loss: 0.900813102722168; CER: 0.05341880023479462; WER: 0.21367521584033966; val_loss: 5.0438337326049805; val_CER: 0.27115386724472046; val_WER: 0.7980769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 240ms/step - loss: 0.9008 - CER: 0.0575 - WER: 0.2328 - val_loss: 5.0438 - val_CER: 0.2712 - val_WER: 0.7981 - lr: 9.0000e-04\n",
            "Epoch 176/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8602 - CER: 0.0497 - WER: 0.1928\n",
            "Epoch 176: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 175; loss: 0.8602138757705688; CER: 0.0525641068816185; WER: 0.20192307233810425; val_loss: 0.3286213278770447; val_CER: 0.01923076994717121; val_WER: 0.09615384787321091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 176: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "15/15 [==============================] - 4s 215ms/step - loss: 0.8602 - CER: 0.0499 - WER: 0.1934 - val_loss: 0.3286 - val_CER: 0.0192 - val_WER: 0.0962 - lr: 9.0000e-04\n",
            "Epoch 177/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.9329 - CER: 0.0597 - WER: 0.2291\n",
            "Epoch 177: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 176; loss: 0.9329352974891663; CER: 0.06111111864447594; WER: 0.22756409645080566; val_loss: 0.32768237590789795; val_CER: 0.015384615398943424; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 0.9329 - CER: 0.0598 - WER: 0.2290 - val_loss: 0.3277 - val_CER: 0.0154 - val_WER: 0.0769 - lr: 8.1000e-04\n",
            "Epoch 178/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8718 - CER: 0.0508 - WER: 0.2076\n",
            "Epoch 178: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 177; loss: 0.8718358278274536; CER: 0.05405982583761215; WER: 0.21260683238506317; val_loss: 0.2759823203086853; val_CER: 0.015384615398943424; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 193ms/step - loss: 0.8718 - CER: 0.0510 - WER: 0.2080 - val_loss: 0.2760 - val_CER: 0.0154 - val_WER: 0.0769 - lr: 8.1000e-04\n",
            "Epoch 179/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8134 - CER: 0.0471 - WER: 0.1818\n",
            "Epoch 179: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 178; loss: 0.8133753538131714; CER: 0.0476495660841465; WER: 0.19017094373703003; val_loss: 0.2317020297050476; val_CER: 0.011538461782038212; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 254ms/step - loss: 0.8134 - CER: 0.0472 - WER: 0.1823 - val_loss: 0.2317 - val_CER: 0.0115 - val_WER: 0.0481 - lr: 8.1000e-04\n",
            "Epoch 180/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8400 - CER: 0.0533 - WER: 0.1898\n",
            "Epoch 180: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 179; loss: 0.839966893196106; CER: 0.049145299941301346; WER: 0.18482905626296997; val_loss: 4.376620769500732; val_CER: 0.21538463234901428; val_WER: 0.7307692170143127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 194ms/step - loss: 0.8400 - CER: 0.0530 - WER: 0.1894 - val_loss: 4.3766 - val_CER: 0.2154 - val_WER: 0.7308 - lr: 8.1000e-04\n",
            "Epoch 181/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.8015 - CER: 0.0522 - WER: 0.2086\n",
            "Epoch 181: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 180; loss: 0.8015268445014954; CER: 0.05170939862728119; WER: 0.21153846383094788; val_loss: 0.3884878158569336; val_CER: 0.013461538590490818; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 202ms/step - loss: 0.8015 - CER: 0.0522 - WER: 0.2088 - val_loss: 0.3885 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 182/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7420 - CER: 0.0539 - WER: 0.1930\n",
            "Epoch 182: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 181; loss: 0.7419721484184265; CER: 0.045085471123456955; WER: 0.17307692766189575; val_loss: 0.3970807194709778; val_CER: 0.01923076994717121; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 5s 265ms/step - loss: 0.7420 - CER: 0.0534 - WER: 0.1918 - val_loss: 0.3971 - val_CER: 0.0192 - val_WER: 0.0769 - lr: 8.1000e-04\n",
            "Epoch 183/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7934 - CER: 0.0404 - WER: 0.1614\n",
            "Epoch 183: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 182; loss: 0.7933860421180725; CER: 0.04893162474036217; WER: 0.1805555522441864; val_loss: 7.895238876342773; val_CER: 0.35576921701431274; val_WER: 0.8653846383094788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 197ms/step - loss: 0.7934 - CER: 0.0409 - WER: 0.1626 - val_loss: 7.8952 - val_CER: 0.3558 - val_WER: 0.8654 - lr: 8.1000e-04\n",
            "Epoch 184/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7676 - CER: 0.0446 - WER: 0.1725\n",
            "Epoch 184: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 183; loss: 0.7676272392272949; CER: 0.04337606579065323; WER: 0.16880342364311218; val_loss: 0.3363085687160492; val_CER: 0.013461539521813393; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 196ms/step - loss: 0.7676 - CER: 0.0445 - WER: 0.1723 - val_loss: 0.3363 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 185/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7096 - CER: 0.0474 - WER: 0.1835\n",
            "Epoch 185: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 184; loss: 0.7096209526062012; CER: 0.044871799647808075; WER: 0.17841880023479462; val_loss: 0.2964610457420349; val_CER: 0.015384615398943424; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 259ms/step - loss: 0.7096 - CER: 0.0472 - WER: 0.1832 - val_loss: 0.2965 - val_CER: 0.0154 - val_WER: 0.0673 - lr: 8.1000e-04\n",
            "Epoch 186/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7636 - CER: 0.0485 - WER: 0.1753\n",
            "Epoch 186: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 185; loss: 0.7635585069656372; CER: 0.04871794953942299; WER: 0.18910256028175354; val_loss: 9.91773796081543; val_CER: 0.4423076808452606; val_WER: 0.932692289352417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 0.7636 - CER: 0.0485 - WER: 0.1762 - val_loss: 9.9177 - val_CER: 0.4423 - val_WER: 0.9327 - lr: 8.1000e-04\n",
            "Epoch 187/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7971 - CER: 0.0540 - WER: 0.2109\n",
            "Epoch 187: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 186; loss: 0.7971180081367493; CER: 0.05042735114693642; WER: 0.20299145579338074; val_loss: 6.33900785446167; val_CER: 0.3076923191547394; val_WER: 0.817307710647583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 202ms/step - loss: 0.7971 - CER: 0.0537 - WER: 0.2104 - val_loss: 6.3390 - val_CER: 0.3077 - val_WER: 0.8173 - lr: 8.1000e-04\n",
            "Epoch 188/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7894 - CER: 0.0469 - WER: 0.1821\n",
            "Epoch 188: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 187; loss: 0.7893537878990173; CER: 0.04743589833378792; WER: 0.18696580827236176; val_loss: 8.400391578674316; val_CER: 0.39807695150375366; val_WER: 0.8942307829856873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 240ms/step - loss: 0.7894 - CER: 0.0469 - WER: 0.1825 - val_loss: 8.4004 - val_CER: 0.3981 - val_WER: 0.8942 - lr: 8.1000e-04\n",
            "Epoch 189/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6925 - CER: 0.0461 - WER: 0.1992\n",
            "Epoch 189: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 188; loss: 0.6925120949745178; CER: 0.04508547484874725; WER: 0.1794871836900711; val_loss: 10.633700370788574; val_CER: 0.4403845965862274; val_WER: 0.9230769276618958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 205ms/step - loss: 0.6925 - CER: 0.0461 - WER: 0.1980 - val_loss: 10.6337 - val_CER: 0.4404 - val_WER: 0.9231 - lr: 8.1000e-04\n",
            "Epoch 190/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6940 - CER: 0.0504 - WER: 0.2084\n",
            "Epoch 190: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 189; loss: 0.6940377354621887; CER: 0.04444444179534912; WER: 0.18269230425357819; val_loss: 0.2410142421722412; val_CER: 0.011538461782038212; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 0.6940 - CER: 0.0500 - WER: 0.2068 - val_loss: 0.2410 - val_CER: 0.0115 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 191/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6539 - CER: 0.0367 - WER: 0.1486\n",
            "Epoch 191: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 190; loss: 0.6539294719696045; CER: 0.039743587374687195; WER: 0.16132478415966034; val_loss: 0.31855177879333496; val_CER: 0.011538461782038212; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 194ms/step - loss: 0.6539 - CER: 0.0369 - WER: 0.1494 - val_loss: 0.3186 - val_CER: 0.0115 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 192/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6798 - CER: 0.0447 - WER: 0.1807\n",
            "Epoch 192: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 191; loss: 0.6797627806663513; CER: 0.0416666716337204; WER: 0.16880342364311218; val_loss: 0.30547380447387695; val_CER: 0.013461539521813393; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 187ms/step - loss: 0.6798 - CER: 0.0445 - WER: 0.1799 - val_loss: 0.3055 - val_CER: 0.0135 - val_WER: 0.0673 - lr: 8.1000e-04\n",
            "Epoch 193/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7066 - CER: 0.0412 - WER: 0.1760\n",
            "Epoch 193: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 192; loss: 0.7065964937210083; CER: 0.0446581169962883; WER: 0.18910256028175354; val_loss: 0.25963541865348816; val_CER: 0.015384615398943424; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 204ms/step - loss: 0.7066 - CER: 0.0415 - WER: 0.1768 - val_loss: 0.2596 - val_CER: 0.0154 - val_WER: 0.0769 - lr: 8.1000e-04\n",
            "Epoch 194/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6284 - CER: 0.0362 - WER: 0.1515\n",
            "Epoch 194: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 193; loss: 0.6283506751060486; CER: 0.036538463085889816; WER: 0.14957265555858612; val_loss: 0.31981346011161804; val_CER: 0.011538461782038212; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 234ms/step - loss: 0.6284 - CER: 0.0362 - WER: 0.1514 - val_loss: 0.3198 - val_CER: 0.0115 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 195/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6746 - CER: 0.0453 - WER: 0.1904\n",
            "Epoch 195: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 194; loss: 0.6745919585227966; CER: 0.04316239431500435; WER: 0.1794871836900711; val_loss: 0.36021530628204346; val_CER: 0.009615384973585606; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 207ms/step - loss: 0.6746 - CER: 0.0452 - WER: 0.1897 - val_loss: 0.3602 - val_CER: 0.0096 - val_WER: 0.0481 - lr: 8.1000e-04\n",
            "Epoch 196/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.7071 - CER: 0.0470 - WER: 0.2065\n",
            "Epoch 196: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 195; loss: 0.7071285843849182; CER: 0.04700854793190956; WER: 0.1944444477558136; val_loss: 0.23253050446510315; val_CER: 0.013461538590490818; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 196: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.7071 - CER: 0.0470 - WER: 0.2057 - val_loss: 0.2325 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 8.1000e-04\n",
            "Epoch 197/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6613 - CER: 0.0422 - WER: 0.1675\n",
            "Epoch 197: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 196; loss: 0.6613377332687378; CER: 0.04038462042808533; WER: 0.16132478415966034; val_loss: 0.24691234529018402; val_CER: 0.011538461782038212; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 267ms/step - loss: 0.6613 - CER: 0.0420 - WER: 0.1671 - val_loss: 0.2469 - val_CER: 0.0115 - val_WER: 0.0481 - lr: 7.2900e-04\n",
            "Epoch 198/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6392 - CER: 0.0376 - WER: 0.1627\n",
            "Epoch 198: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 197; loss: 0.6392486691474915; CER: 0.03888888657093048; WER: 0.16025641560554504; val_loss: 0.34809866547584534; val_CER: 0.011538461782038212; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 202ms/step - loss: 0.6392 - CER: 0.0377 - WER: 0.1626 - val_loss: 0.3481 - val_CER: 0.0115 - val_WER: 0.0481 - lr: 7.2900e-04\n",
            "Epoch 199/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5714 - CER: 0.0385 - WER: 0.1524\n",
            "Epoch 199: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 198; loss: 0.5713648796081543; CER: 0.03504273667931557; WER: 0.14102564752101898; val_loss: 0.28415805101394653; val_CER: 0.013461539521813393; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 8s 528ms/step - loss: 0.5714 - CER: 0.0383 - WER: 0.1517 - val_loss: 0.2842 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 7.2900e-04\n",
            "Epoch 200/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6043 - CER: 0.0364 - WER: 0.1514\n",
            "Epoch 200: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 199; loss: 0.604300856590271; CER: 0.036538463085889816; WER: 0.14636752009391785; val_loss: 0.25549355149269104; val_CER: 0.011538461782038212; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 189ms/step - loss: 0.6043 - CER: 0.0364 - WER: 0.1511 - val_loss: 0.2555 - val_CER: 0.0115 - val_WER: 0.0481 - lr: 7.2900e-04\n",
            "Epoch 201/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6729 - CER: 0.0420 - WER: 0.1558\n",
            "Epoch 201: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 200; loss: 0.6728639006614685; CER: 0.04444444552063942; WER: 0.17307692766189575; val_loss: 0.2955573499202728; val_CER: 0.011538461782038212; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 183ms/step - loss: 0.6729 - CER: 0.0422 - WER: 0.1569 - val_loss: 0.2956 - val_CER: 0.0115 - val_WER: 0.0481 - lr: 7.2900e-04\n",
            "Epoch 202/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6032 - CER: 0.0328 - WER: 0.1276\n",
            "Epoch 202: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 201; loss: 0.6031712293624878; CER: 0.033760685473680496; WER: 0.13461539149284363; val_loss: 0.3473780155181885; val_CER: 0.021153846755623817; val_WER: 0.07692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 192ms/step - loss: 0.6032 - CER: 0.0328 - WER: 0.1280 - val_loss: 0.3474 - val_CER: 0.0212 - val_WER: 0.0769 - lr: 7.2900e-04\n",
            "Epoch 203/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6634 - CER: 0.0471 - WER: 0.1848\n",
            "Epoch 203: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 202; loss: 0.6633853912353516; CER: 0.04358974099159241; WER: 0.17200854420661926; val_loss: 0.35136279463768005; val_CER: 0.013461539521813393; val_WER: 0.048076923936605453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 250ms/step - loss: 0.6634 - CER: 0.0468 - WER: 0.1840 - val_loss: 0.3514 - val_CER: 0.0135 - val_WER: 0.0481 - lr: 7.2900e-04\n",
            "Epoch 204/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6085 - CER: 0.0356 - WER: 0.1527\n",
            "Epoch 204: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 203; loss: 0.608453094959259; CER: 0.03589743375778198; WER: 0.1517094075679779; val_loss: 0.2934030294418335; val_CER: 0.011538461782038212; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 186ms/step - loss: 0.6085 - CER: 0.0357 - WER: 0.1527 - val_loss: 0.2934 - val_CER: 0.0115 - val_WER: 0.0577 - lr: 7.2900e-04\n",
            "Epoch 205/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.5955 - CER: 0.0371 - WER: 0.1550\n",
            "Epoch 205: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 204; loss: 0.5954549908638; CER: 0.03589743375778198; WER: 0.14529915153980255; val_loss: 0.319350928068161; val_CER: 0.017307691276073456; val_WER: 0.06730769574642181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 3s 187ms/step - loss: 0.5955 - CER: 0.0371 - WER: 0.1544 - val_loss: 0.3194 - val_CER: 0.0173 - val_WER: 0.0673 - lr: 7.2900e-04\n",
            "Epoch 206/1000\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.6515 - CER: 0.0364 - WER: 0.1610\n",
            "Epoch 206: val_CER did not improve from 0.00962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Epoch 205; loss: 0.6514748334884644; CER: 0.03995727002620697; WER: 0.16239316761493683; val_loss: 0.40017804503440857; val_CER: 0.013461539521813393; val_WER: 0.057692307978868484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r15/15 [==============================] - 4s 211ms/step - loss: 0.6515 - CER: 0.0366 - WER: 0.1611 - val_loss: 0.4002 - val_CER: 0.0135 - val_WER: 0.0577 - lr: 7.2900e-04\n",
            "Epoch 206: early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tf2onnx.tfonnx:Using tensorflow=2.12.0, onnx=1.13.1, tf2onnx=1.14.0/8f8d49\n",
            "INFO:tf2onnx.tfonnx:Using opset <onnx, 15>\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 0 values for constant folding\n",
            "INFO:tf2onnx.tf_utils:Computed 2 values for constant folding\n",
            "INFO:tf2onnx.tfonnx:folding node using tf type=StridedSlice, name=model/bidirectional/forward_lstm/PartitionedCall/strided_slice\n",
            "INFO:tf2onnx.tfonnx:folding node using tf type=StridedSlice, name=model/bidirectional/backward_lstm/PartitionedCall/strided_slice\n",
            "INFO:tf2onnx.optimizer:Optimizing ONNX model\n",
            "INFO:tf2onnx.optimizer:After optimization: BatchNormalization -18 (18->0), Cast -4 (11->7), Concat -4 (10->6), Const -128 (194->66), Expand -3 (4->1), Gather +2 (2->4), Identity -2 (2->0), Shape -1 (4->3), Slice -1 (5->4), Squeeze -3 (5->2), Transpose -83 (87->4), Unsqueeze -14 (17->3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try: [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices('GPU')]\n",
        "except: pass\n",
        "\n",
        "def download_and_unzip(url, extract_to='Datasets'):\n",
        "    http_response = urlopen(url)\n",
        "    zipfile = ZipFile(BytesIO(http_response.read()))\n",
        "    zipfile.extractall(path=extract_to)\n",
        "\n",
        "if not os.path.exists(os.path.join('Datasets', 'captcha_images_v2')):\n",
        "    download_and_unzip('https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip', extract_to='Datasets')\n",
        "\n",
        "# Create a list of all the images and labels in the dataset\n",
        "dataset, vocab, max_len = [], set(), 0\n",
        "captcha_path = os.path.join('Datasets', 'captcha_images_v2')\n",
        "for file in os.listdir(captcha_path):\n",
        "    file_path = os.path.join(captcha_path, file)\n",
        "    label = os.path.splitext(file)[0] # Get the file name without the extension\n",
        "    dataset.append([file_path, label])\n",
        "    vocab.update(list(label))\n",
        "    max_len = max(max_len, len(label))\n",
        "\n",
        "\n",
        "\n",
        "class ModelConfigs(BaseModelConfigs):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model_path = os.path.join('Models/02_captcha_to_text', datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
        "        self.vocab = ''\n",
        "        self.height = 50\n",
        "        self.width = 200\n",
        "        self.max_text_length = 0\n",
        "        self.batch_size = 64\n",
        "        self.learning_rate = 1e-3\n",
        "        self.train_epochs = 1000\n",
        "        self.train_workers = 20\n",
        "\n",
        "configs = ModelConfigs()\n",
        "\n",
        "# Save vocab and maximum text length to configs\n",
        "configs.vocab = \"\".join(vocab)\n",
        "configs.max_text_length = max_len\n",
        "configs.save()\n",
        "\n",
        "# Create a data provider for the dataset\n",
        "\n",
        "data_provider = DataProvider(\n",
        "    dataset=dataset,\n",
        "    skip_validation=True,\n",
        "    batch_size=configs.batch_size,\n",
        "    data_preprocessors=[ImageReader()],\n",
        "    transformers=[\n",
        "        ImageResizer(configs.width, configs.height),\n",
        "        LabelIndexer(configs.vocab),\n",
        "        LabelPadding(max_word_length=configs.max_text_length, padding_value=len(configs.vocab))\n",
        "        ],\n",
        ")\n",
        "# Split the dataset into training and validation sets\n",
        "train_data_provider, val_data_provider = data_provider.split(split = 0.9)\n",
        "\n",
        "# Augment training data with random brightness, rotation and erode/dilate\n",
        "train_data_provider.augmentors = [RandomBrightness(), RandomRotate(), RandomErodeDilate()]\n",
        "\n",
        "# Creating TensorFlow model architecture\n",
        "model = train_model(\n",
        "    input_dim = (configs.height, configs.width, 3),\n",
        "    output_dim = len(configs.vocab),\n",
        ")\n",
        "\n",
        "\n",
        "# Compile the model and print summary\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate), \n",
        "    loss=CTCloss(), \n",
        "    metrics=[CWERMetric(padding_token=len(configs.vocab))],\n",
        "    run_eagerly=False\n",
        ")\n",
        "model.summary(line_length=110)\n",
        "\n",
        "# Define path to save the model\n",
        "os.makedirs(configs.model_path, exist_ok=True)\n",
        "\n",
        "# Define callbacks\n",
        "earlystopper = EarlyStopping(monitor='val_CER', patience=50, verbose=1)\n",
        "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor='val_CER', verbose=1, save_best_only=True, mode='min')\n",
        "trainLogger = TrainLogger(configs.model_path)\n",
        "tb_callback = TensorBoard(f'{configs.model_path}/logs', update_freq=1)\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_CER', factor=0.9, min_delta=1e-10, patience=20, verbose=1, mode='auto')\n",
        "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_data_provider,\n",
        "    validation_data=val_data_provider,\n",
        "    epochs=configs.train_epochs,\n",
        "    callbacks=[earlystopper, checkpoint, trainLogger, reduceLROnPlat, tb_callback, model2onnx],\n",
        "    workers=configs.train_workers\n",
        ")\n",
        "\n",
        "# Save training and validation datasets as csv files\n",
        "train_data_provider.to_csv(os.path.join(configs.model_path, 'train.csv'))\n",
        "val_data_provider.to_csv(os.path.join(configs.model_path, 'val.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaaFv0vSqgpH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyMnW3eTqh64",
        "outputId": "1645e124-cbdf-4c59-e161-cf3053ea82c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        }
      ],
      "source": [
        "#utils\n",
        "    \n",
        "def ctc_decoder(predictions: np.ndarray, chars: typing.Union[str, list]) -> typing.List[str]:\n",
        "    ''' CTC greedy decoder for predictions\n",
        "    \n",
        "    Args:\n",
        "        predictions (np.ndarray): predictions from model\n",
        "        chars (typing.Union[str, list]): list of characters\n",
        "\n",
        "    Returns:\n",
        "        typing.List[str]: list of words\n",
        "    '''\n",
        "    # use argmax to find the index of the highest probability\n",
        "    argmax_preds = np.argmax(predictions, axis=-1)\n",
        "    \n",
        "    # use groupby to find continuous same indexes\n",
        "    grouped_preds = [[k for k,_ in groupby(preds)] for preds in argmax_preds]\n",
        "\n",
        "    # convert indexes to chars\n",
        "    texts = [\"\".join([chars[k] for k in group if k < len(chars)]) for group in grouped_preds]\n",
        "\n",
        "    return texts\n",
        "\n",
        "\n",
        "def edit_distance(prediction_tokens: typing.List[str], reference_tokens: typing.List[str]) -> int:\n",
        "    \"\"\" Standard dynamic programming algorithm to compute the Levenshtein Edit Distance Algorithm\n",
        "\n",
        "    Args:\n",
        "        prediction_tokens: A tokenized predicted sentence\n",
        "        reference_tokens: A tokenized reference sentence\n",
        "    Returns:\n",
        "        Edit distance between the predicted sentence and the reference sentence\n",
        "    \"\"\"\n",
        "    # Initialize a matrix to store the edit distances\n",
        "    dp = [[0] * (len(reference_tokens) + 1) for _ in range(len(prediction_tokens) + 1)]\n",
        "\n",
        "    # Fill the first row and column with the number of insertions needed\n",
        "    for i in range(len(prediction_tokens) + 1):\n",
        "        dp[i][0] = i\n",
        "    \n",
        "    dp[0] = [j for j in range(len(reference_tokens) + 1)]\n",
        "\n",
        "    # Iterate through the prediction and reference tokens\n",
        "    for i, p_tok in enumerate(prediction_tokens):\n",
        "        for j, r_tok in enumerate(reference_tokens):\n",
        "            # If the tokens are the same, the edit distance is the same as the previous entry\n",
        "            if p_tok == r_tok:\n",
        "                dp[i+1][j+1] = dp[i][j]\n",
        "            # If the tokens are different, the edit distance is the minimum of the previous entries plus 1\n",
        "            else:\n",
        "                dp[i+1][j+1] = min(dp[i][j+1], dp[i+1][j], dp[i][j]) + 1\n",
        "\n",
        "    # Return the final entry in the matrix as the edit distance     \n",
        "    return dp[-1][-1]\n",
        "\n",
        "def get_cer(\n",
        "    preds: typing.Union[str, typing.List[str]],\n",
        "    target: typing.Union[str, typing.List[str]],\n",
        "    ) -> float:\n",
        "    \"\"\" Update the cer score with the current set of references and predictions.\n",
        "\n",
        "    Args:\n",
        "        preds (typing.Union[str, typing.List[str]]): list of predicted sentences\n",
        "        target (typing.Union[str, typing.List[str]]): list of target words\n",
        "\n",
        "    Returns:\n",
        "        Character error rate score\n",
        "    \"\"\"\n",
        "    if isinstance(preds, str):\n",
        "        preds = [preds]\n",
        "    if isinstance(target, str):\n",
        "        target = [target]\n",
        "\n",
        "    total, errors = 0, 0\n",
        "    for pred_tokens, tgt_tokens in zip(preds, target):\n",
        "        errors += edit_distance(list(pred_tokens), list(tgt_tokens))\n",
        "        total += len(tgt_tokens)\n",
        "\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "\n",
        "    cer = errors / total\n",
        "\n",
        "    return cer\n",
        "\n",
        "def get_wer(\n",
        "    preds: typing.Union[str, typing.List[str]],\n",
        "    target: typing.Union[str, typing.List[str]],\n",
        "    ) -> float:\n",
        "    \"\"\" Update the wer score with the current set of references and predictions.\n",
        "\n",
        "    Args:\n",
        "        target (typing.Union[str, typing.List[str]]): string of target sentence or list of target words\n",
        "        preds (typing.Union[str, typing.List[str]]): string of predicted sentence or list of predicted words\n",
        "\n",
        "    Returns:\n",
        "        Word error rate score\n",
        "    \"\"\"\n",
        "    if isinstance(preds, str):\n",
        "        preds = preds.split()\n",
        "    if isinstance(target, str):\n",
        "        target = target.split()\n",
        "\n",
        "    errors = edit_distance(preds, target)\n",
        "    total_words = len(target)\n",
        "\n",
        "    if total_words == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return errors / total_words\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    c1 = 'ROKAS'\n",
        "    c2 = 'ROKAZ '\n",
        "\n",
        "    w1 = 'ROKAS GOOD BOY'\n",
        "    w2 = 'ROKAZ IS A GOOD BOY'\n",
        "\n",
        "    cer = get_cer(c1, c2)\n",
        "    wer = get_wer(w1, w2)\n",
        "\n",
        "    print(wer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICrFbIkfqh3M",
        "outputId": "04c1b337-1b19-4d83-d49e-e3c3b107d874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 14/104 [00:00<00:00, 131.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/5dxnm.png, Label: 5dxnm, Prediction: 5dxnm, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gnbde.png, Label: gnbde, Prediction: gnbde, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/c2fb7.png, Label: c2fb7, Prediction: c2fb7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/8npe3.png, Label: 8npe3, Prediction: 8npe3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/c7gb3.png, Label: c7gb3, Prediction: c7gb3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mx8bb.png, Label: mx8bb, Prediction: mx8bb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/men4f.png, Label: men4f, Prediction: men4f, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n6xc5.png, Label: n6xc5, Prediction: n6xc5, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/enn7n.png, Label: enn7n, Prediction: enn7n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/d22n7.png, Label: d22n7, Prediction: d22n7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/74eyg.png, Label: 74eyg, Prediction: 74eyg, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ydg8n.png, Label: ydg8n, Prediction: ydg8n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gf2g4.png, Label: gf2g4, Prediction: gf2g4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/378e5.png, Label: 378e5, Prediction: 378e5, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/d236n.png, Label: d236n, Prediction: d236n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/p2ym2.png, Label: p2ym2, Prediction: p2ym2, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/5n3w4.png, Label: 5n3w4, Prediction: 5n3w4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/f6ww8.png, Label: f6ww8, Prediction: f6ww8, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/2wx73.png, Label: 2wx73, Prediction: 2wx73, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/m5meg.png, Label: m5meg, Prediction: m5meg, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xwx7d.png, Label: xwx7d, Prediction: xwx7d, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/7634y.png, Label: 7634y, Prediction: 7634y, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nmy2x.png, Label: nmy2x, Prediction: nmy2x, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ppwyd.png, Label: ppwyd, Prediction: ppwyd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/yf347.png, Label: yf347, Prediction: yf347, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ewnx8.png, Label: ewnx8, Prediction: ewnx8, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/325fb.png, Label: 325fb, Prediction: 325fb, CER: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 41/104 [00:00<00:00, 127.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/7wnpm.png, Label: 7wnpm, Prediction: 3wnpm, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/4nnf3.png, Label: 4nnf3, Prediction: 4nnf3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/77387.png, Label: 77387, Prediction: 7387, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/xnnc3.png, Label: xnnc3, Prediction: xnnc3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xbem6.png, Label: xbem6, Prediction: xbem6, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mdyp7.png, Label: mdyp7, Prediction: mdyp7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/47m2b.png, Label: 47m2b, Prediction: 47m2b, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ndecc.png, Label: ndecc, Prediction: ndecc, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n5w5g.png, Label: n5w5g, Prediction: n5w5g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/32cnn.png, Label: 32cnn, Prediction: 32cnn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/y53c2.png, Label: y53c2, Prediction: y53c2, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/bdg84.png, Label: bdg84, Prediction: bdg84, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ccn2x.png, Label: ccn2x, Prediction: ccn2x, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/2n73f.png, Label: 2n73f, Prediction: 2n73f, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/m4g8g.png, Label: m4g8g, Prediction: m4g8g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/36bc2.png, Label: 36bc2, Prediction: 36bc2, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/p4pde.png, Label: p4pde, Prediction: p4pde, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/excmn.png, Label: excmn, Prediction: excmn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ef4np.png, Label: ef4np, Prediction: ef4np, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/x3deb.png, Label: x3deb, Prediction: x3deb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/4exnn.png, Label: 4exnn, Prediction: 4exnn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/pwmbn.png, Label: pwmbn, Prediction: pwmbn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/efe62.png, Label: efe62, Prediction: efe62, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mpmy5.png, Label: mpmy5, Prediction: mpmy5, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nb267.png, Label: nb267, Prediction: nb267, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/cdcb3.png, Label: cdcb3, Prediction: edcb3, CER: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 68/104 [00:00<00:00, 127.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/f2m8n.png, Label: f2m8n, Prediction: f3m8n, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/3n2b4.png, Label: 3n2b4, Prediction: 3n2b4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/7xcyd.png, Label: 7xcyd, Prediction: 7xcyd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/24f6w.png, Label: 24f6w, Prediction: 24f6w, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/2en7g.png, Label: 2en7g, Prediction: 2en7g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n8ydd.png, Label: n8ydd, Prediction: n8ydd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/6n5fd.png, Label: 6n5fd, Prediction: 6n5fd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/pme86.png, Label: pme86, Prediction: pme86, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ncw4g.png, Label: ncw4g, Prediction: ncw4g, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/7fde7.png, Label: 7fde7, Prediction: 7fde7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/56c34.png, Label: 56c34, Prediction: 56c34, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/wddcp.png, Label: wddcp, Prediction: wddcp, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/73mnx.png, Label: 73mnx, Prediction: 73mnx, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/664nf.png, Label: 664nf, Prediction: 664nf, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xnfx5.png, Label: xnfx5, Prediction: xnfx5, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/mmc5n.png, Label: mmc5n, Prediction: mmc5n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/wc2bd.png, Label: wc2bd, Prediction: wc2bd, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/2w4y7.png, Label: 2w4y7, Prediction: 2w4y7, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/wnmyn.png, Label: wnmyn, Prediction: wnmyn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/44fyb.png, Label: 44fyb, Prediction: 44fyb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/myc3c.png, Label: myc3c, Prediction: myc3c, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/6end3.png, Label: 6end3, Prediction: 6end3, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gymmn.png, Label: gymmn, Prediction: gymmm, CER: 0.2\n",
            "Image: Datasets/captcha_images_v2/4egem.png, Label: 4egem, Prediction: 4egem, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/78eec.png, Label: 78eec, Prediction: 78eec, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/7m8px.png, Label: 7m8px, Prediction: 7m8px, CER: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104/104 [00:00<00:00, 127.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: Datasets/captcha_images_v2/w6pxy.png, Label: w6pxy, Prediction: w6pxy, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/63824.png, Label: 63824, Prediction: 63824, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/ng756.png, Label: ng756, Prediction: ng756, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/5ywwf.png, Label: 5ywwf, Prediction: 5ywwf, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/pn7pn.png, Label: pn7pn, Prediction: pn7pn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/bmxpe.png, Label: bmxpe, Prediction: bmxpe, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/d4n82.png, Label: d4n82, Prediction: d4n82, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/b4d7c.png, Label: b4d7c, Prediction: b4d7c, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/xgcxy.png, Label: xgcxy, Prediction: xgcxy, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/bnc5f.png, Label: bnc5f, Prediction: bnc5f, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/nwncn.png, Label: nwncn, Prediction: nwncn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/3cpwb.png, Label: 3cpwb, Prediction: 3cpwb, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gnf85.png, Label: gnf85, Prediction: gnf85, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/e7nx4.png, Label: e7nx4, Prediction: e7nx4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/573bn.png, Label: 573bn, Prediction: 573bn, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/n4cpy.png, Label: n4cpy, Prediction: n4cpy, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/3p67n.png, Label: 3p67n, Prediction: 3p67n, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/c353e.png, Label: c353e, Prediction: c353e, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/53wb8.png, Label: 53wb8, Prediction: 53wb8, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/yf28d.png, Label: yf28d, Prediction: yf28d, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/cnex4.png, Label: cnex4, Prediction: cnex4, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/gcfgp.png, Label: gcfgp, Prediction: gcfgp, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/445cc.png, Label: 445cc, Prediction: 445cc, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/55w5c.png, Label: 55w5c, Prediction: 55w5c, CER: 0.0\n",
            "Image: Datasets/captcha_images_v2/y2xg4.png, Label: y2xg4, Prediction: y2xg4, CER: 0.0\n",
            "Average CER: 0.009615384615384616\n",
            "Accuracy of Model : 99.03846153846153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ImageToWordModel(OnnxInferenceModel):\n",
        "    def __init__(self, char_list: typing.Union[str, list], *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.char_list = char_list\n",
        "\n",
        "    def predict(self, image: np.ndarray):\n",
        "        image = cv2.resize(image, self.input_shape[:2][::-1])\n",
        "\n",
        "        image_pred = np.expand_dims(image, axis=0).astype(np.float32)\n",
        "\n",
        "        preds = self.model.run(None, {self.input_name: image_pred})[0]\n",
        "\n",
        "        text = ctc_decoder(preds, self.char_list)[0]\n",
        "\n",
        "        return text\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    configs = BaseModelConfigs.load(\"/content/Models/02_captcha_to_text/202305021409/configs.yaml\")\n",
        "\n",
        "    model = ImageToWordModel(model_path=configs.model_path, char_list=configs.vocab)\n",
        "\n",
        "    df = pd.read_csv(\"/content/Models/02_captcha_to_text/202305021409/val.csv\").values.tolist()\n",
        "\n",
        "    accum_cer = []\n",
        "    for image_path, label in tqdm(df):\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        prediction_text = model.predict(image)\n",
        "\n",
        "        cer = get_cer(prediction_text, label)\n",
        "        print(f\"Image: {image_path}, Label: {label}, Prediction: {prediction_text}, CER: {cer}\")\n",
        "\n",
        "        accum_cer.append(cer)\n",
        "\n",
        "    print(f\"Average CER: {np.average(accum_cer)}\")\n",
        "    print(f\"Accuracy of Model : {100-(100*np.average(accum_cer))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHG-ehXiqhz7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpig2bj0qhww"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfHmbpfWqht_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0_1Umxeqhqf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1L-3Db_qhnS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkkPSTcaqhjy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HbtOuM0qhPO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}